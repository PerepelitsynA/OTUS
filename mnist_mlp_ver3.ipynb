{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "mnist_mlp-8858-e56a62.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ_tNktO7Gl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from itertools import islice\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# фиксируем все seed\n",
        "random.seed(170)\n",
        "np.random.seed(170)\n",
        "torch.manual_seed(170)\n",
        "torch.cuda.manual_seed(170)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74OWc9XSK8lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVfZuH3yMAPo",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VTOtD-SJEsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utils\n",
        "import torch\n",
        "from torch import utils\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,)),\n",
        "           ])\n",
        "\n",
        "def mnist(batch_size=10, shuffle=True, transform=mnist_transform, path='./MNIST_data'):\n",
        "    train_data = datasets.MNIST(path, train=True, download=True, transform=transform)\n",
        "    test_data = datasets.MNIST(path, train=False, download=True, transform=transform)\n",
        "    train_loader = utils.data.DataLoader(train_data, batch_size=batch_size,num_workers=4,\\\n",
        "                                         sampler = torch.utils.data.sampler.RandomSampler([*range(1000)]))\n",
        "    test_loader = utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False,num_workers=4,\\\n",
        "                                        sampler = torch.utils.data.sampler.RandomSampler([*range(1000)]))\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def plot_mnist(images, shape):\n",
        "    fig = plt.figure(figsize=shape[::-1], dpi=80)\n",
        "    for j in range(1, len(images) + 1):\n",
        "        ax = fig.add_subplot(shape[0], shape[1], j)\n",
        "        ax.matshow(images[j - 1, 0, :, :], cmap = matplotlib.cm.binary)\n",
        "        plt.xticks(np.array([]))\n",
        "        plt.yticks(np.array([]))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jLZBeEl7Gl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader = mnist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF-bY6NY7Gl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, log_softmax=False):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "        self.log_softmax = log_softmax\n",
        "        self.optim = optim.SGD(self.parameters(), lr=0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        if self.log_softmax:\n",
        "            x = F.log_softmax(x, dim=1)\n",
        "        else:\n",
        "            x = torch.log(F.softmax(x, dim=1))\n",
        "        return x\n",
        "    \n",
        "    def loss(self, output, target, **kwargs):\n",
        "        self._loss = F.nll_loss(output, target, **kwargs)\n",
        "        return self._loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqe8ixht7GmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, models):\n",
        "    pred_m= []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # переводим на gpu, уменьшаем размер выборки\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        for model in models:\n",
        "            model.optim.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = model.loss(output, target)\n",
        "            loss.backward()\n",
        "            model.optim.step()\n",
        "\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct = pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "            pred_m.append(correct)\n",
        "            \n",
        "        if batch_idx % 50 == 0:\n",
        "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader) * len(data),\n",
        "                100. * batch_idx / len(train_loader) )\n",
        "            losses = ' '.join(['{}: {:.6f}'.format(i, m._loss.item()) for i, m in enumerate(models)])\n",
        "            print(line + losses)\n",
        "            \n",
        "    else:\n",
        "        batch_idx += 1\n",
        "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
        "            epoch, batch_idx * len(data), len(train_loader) * len(data),\n",
        "            100. * batch_idx / len(train_loader) )\n",
        "        losses = ' '.join(['{}: {:.6f}'.format(i, m._loss.item()) for i, m in enumerate(models)])\n",
        "        print(line + losses)\n",
        "        # добавляем расчет среднего значения предсказаний\n",
        "        correct_pct = [c.numpy() / len(data) for c in pred_m]\n",
        "\n",
        "    return models[0]._loss.item(), round(np.mean(correct_pct),2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EVWaW-77GmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# уберем одну из сетей для ускорения расчетов\n",
        "models = [Net(True).to(device)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjRt3I3I7GmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
        "acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, len(test_loader) * test_loader.batch_size, p)\n",
        "line = lambda i, l, c, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
        "\n",
        "def test(models):\n",
        "    test_loss = [0]*len(models)\n",
        "    correct = [0]*len(models)\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            # переводим на gpu\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output = [m(data) for m in models]\n",
        "            for i, m in enumerate(models):\n",
        "                test_loss[i] += m.loss(output[i], target, reduction='sum').item() # sum up batch loss\n",
        "                pred = output[i].data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "                correct[i] += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "    \n",
        "    for i in range(len(models)):\n",
        "        test_loss[i] /= (len(test_loader) * test_loader.batch_size)\n",
        "    correct_pct = [100. * c / (len(test_loader) * test_loader.batch_size) for c in correct]\n",
        "    lines = '\\n'.join([line(i, test_loss[i], correct[i], correct_pct[i]) for i in range(len(models))]) + '\\n'\n",
        "    report = 'Test set:\\n' + lines\n",
        "    \n",
        "    print(report)\n",
        "    return test_loss[0],correct_pct[0]/100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFgYNmz77GmJ",
        "colab_type": "code",
        "outputId": "a19fa63c-a5c3-48da-ccfb-1cc8d6d3c103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "accuracy_test_history = []\n",
        "accuracy_train_history = []\n",
        "\n",
        "for epoch in range(1, 181):\n",
        "    loss_train_,acc_train_ = train(epoch, models) \n",
        "    loss_test_, acc_test_ = test(models)\n",
        "    train_loss_history.append(loss_train_)\n",
        "    test_loss_history.append(loss_test_)\n",
        "    accuracy_test_history.append(acc_test_)\n",
        "    accuracy_train_history.append(acc_train_)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/1000 (0%)]\tLosses 0: 2.300399\n",
            "Train Epoch: 1 [500/1000 (50%)]\tLosses 0: 2.428642\n",
            "Train Epoch: 1 [1000/1000 (100%)]\tLosses 0: 2.250436\n",
            "Test set:\n",
            "0: Loss: 2.2746\tAccuracy: 99/1000 (10%)\n",
            "\n",
            "Train Epoch: 2 [0/1000 (0%)]\tLosses 0: 2.395161\n",
            "Train Epoch: 2 [500/1000 (50%)]\tLosses 0: 1.973040\n",
            "Train Epoch: 2 [1000/1000 (100%)]\tLosses 0: 1.721138\n",
            "Test set:\n",
            "0: Loss: 1.7938\tAccuracy: 339/1000 (34%)\n",
            "\n",
            "Train Epoch: 3 [0/1000 (0%)]\tLosses 0: 1.589839\n",
            "Train Epoch: 3 [500/1000 (50%)]\tLosses 0: 1.259254\n",
            "Train Epoch: 3 [1000/1000 (100%)]\tLosses 0: 1.218598\n",
            "Test set:\n",
            "0: Loss: 2.0820\tAccuracy: 339/1000 (34%)\n",
            "\n",
            "Train Epoch: 4 [0/1000 (0%)]\tLosses 0: 1.400864\n",
            "Train Epoch: 4 [500/1000 (50%)]\tLosses 0: 0.532170\n",
            "Train Epoch: 4 [1000/1000 (100%)]\tLosses 0: 1.100362\n",
            "Test set:\n",
            "0: Loss: 1.1181\tAccuracy: 561/1000 (56%)\n",
            "\n",
            "Train Epoch: 5 [0/1000 (0%)]\tLosses 0: 0.556608\n",
            "Train Epoch: 5 [500/1000 (50%)]\tLosses 0: 0.723539\n",
            "Train Epoch: 5 [1000/1000 (100%)]\tLosses 0: 0.480730\n",
            "Test set:\n",
            "0: Loss: 0.9276\tAccuracy: 686/1000 (69%)\n",
            "\n",
            "Train Epoch: 6 [0/1000 (0%)]\tLosses 0: 1.137328\n",
            "Train Epoch: 6 [500/1000 (50%)]\tLosses 0: 0.365397\n",
            "Train Epoch: 6 [1000/1000 (100%)]\tLosses 0: 0.471789\n",
            "Test set:\n",
            "0: Loss: 1.0495\tAccuracy: 660/1000 (66%)\n",
            "\n",
            "Train Epoch: 7 [0/1000 (0%)]\tLosses 0: 0.326760\n",
            "Train Epoch: 7 [500/1000 (50%)]\tLosses 0: 0.227700\n",
            "Train Epoch: 7 [1000/1000 (100%)]\tLosses 0: 0.260185\n",
            "Test set:\n",
            "0: Loss: 0.7495\tAccuracy: 792/1000 (79%)\n",
            "\n",
            "Train Epoch: 8 [0/1000 (0%)]\tLosses 0: 0.262606\n",
            "Train Epoch: 8 [500/1000 (50%)]\tLosses 0: 0.333636\n",
            "Train Epoch: 8 [1000/1000 (100%)]\tLosses 0: 0.090080\n",
            "Test set:\n",
            "0: Loss: 0.6208\tAccuracy: 829/1000 (83%)\n",
            "\n",
            "Train Epoch: 9 [0/1000 (0%)]\tLosses 0: 0.094148\n",
            "Train Epoch: 9 [500/1000 (50%)]\tLosses 0: 0.024994\n",
            "Train Epoch: 9 [1000/1000 (100%)]\tLosses 0: 0.034955\n",
            "Test set:\n",
            "0: Loss: 0.6125\tAccuracy: 832/1000 (83%)\n",
            "\n",
            "Train Epoch: 10 [0/1000 (0%)]\tLosses 0: 0.044423\n",
            "Train Epoch: 10 [500/1000 (50%)]\tLosses 0: 0.046655\n",
            "Train Epoch: 10 [1000/1000 (100%)]\tLosses 0: 0.484302\n",
            "Test set:\n",
            "0: Loss: 0.6596\tAccuracy: 829/1000 (83%)\n",
            "\n",
            "Train Epoch: 11 [0/1000 (0%)]\tLosses 0: 0.020774\n",
            "Train Epoch: 11 [500/1000 (50%)]\tLosses 0: 0.108458\n",
            "Train Epoch: 11 [1000/1000 (100%)]\tLosses 0: 0.027420\n",
            "Test set:\n",
            "0: Loss: 0.5800\tAccuracy: 847/1000 (85%)\n",
            "\n",
            "Train Epoch: 12 [0/1000 (0%)]\tLosses 0: 0.023027\n",
            "Train Epoch: 12 [500/1000 (50%)]\tLosses 0: 0.018968\n",
            "Train Epoch: 12 [1000/1000 (100%)]\tLosses 0: 0.007808\n",
            "Test set:\n",
            "0: Loss: 0.8112\tAccuracy: 813/1000 (81%)\n",
            "\n",
            "Train Epoch: 13 [0/1000 (0%)]\tLosses 0: 0.007145\n",
            "Train Epoch: 13 [500/1000 (50%)]\tLosses 0: 0.075560\n",
            "Train Epoch: 13 [1000/1000 (100%)]\tLosses 0: 0.018441\n",
            "Test set:\n",
            "0: Loss: 0.7024\tAccuracy: 833/1000 (83%)\n",
            "\n",
            "Train Epoch: 14 [0/1000 (0%)]\tLosses 0: 0.072263\n",
            "Train Epoch: 14 [500/1000 (50%)]\tLosses 0: 0.268354\n",
            "Train Epoch: 14 [1000/1000 (100%)]\tLosses 0: 0.012957\n",
            "Test set:\n",
            "0: Loss: 0.6080\tAccuracy: 849/1000 (85%)\n",
            "\n",
            "Train Epoch: 15 [0/1000 (0%)]\tLosses 0: 0.006889\n",
            "Train Epoch: 15 [500/1000 (50%)]\tLosses 0: 0.009316\n",
            "Train Epoch: 15 [1000/1000 (100%)]\tLosses 0: 0.009724\n",
            "Test set:\n",
            "0: Loss: 0.6537\tAccuracy: 850/1000 (85%)\n",
            "\n",
            "Train Epoch: 16 [0/1000 (0%)]\tLosses 0: 0.006216\n",
            "Train Epoch: 16 [500/1000 (50%)]\tLosses 0: 0.008898\n",
            "Train Epoch: 16 [1000/1000 (100%)]\tLosses 0: 0.006419\n",
            "Test set:\n",
            "0: Loss: 0.6585\tAccuracy: 849/1000 (85%)\n",
            "\n",
            "Train Epoch: 17 [0/1000 (0%)]\tLosses 0: 0.006024\n",
            "Train Epoch: 17 [500/1000 (50%)]\tLosses 0: 0.007567\n",
            "Train Epoch: 17 [1000/1000 (100%)]\tLosses 0: 0.005276\n",
            "Test set:\n",
            "0: Loss: 0.6620\tAccuracy: 848/1000 (85%)\n",
            "\n",
            "Train Epoch: 18 [0/1000 (0%)]\tLosses 0: 0.002586\n",
            "Train Epoch: 18 [500/1000 (50%)]\tLosses 0: 0.006325\n",
            "Train Epoch: 18 [1000/1000 (100%)]\tLosses 0: 0.008707\n",
            "Test set:\n",
            "0: Loss: 0.6851\tAccuracy: 849/1000 (85%)\n",
            "\n",
            "Train Epoch: 19 [0/1000 (0%)]\tLosses 0: 0.004301\n",
            "Train Epoch: 19 [500/1000 (50%)]\tLosses 0: 0.004730\n",
            "Train Epoch: 19 [1000/1000 (100%)]\tLosses 0: 0.011161\n",
            "Test set:\n",
            "0: Loss: 0.6922\tAccuracy: 850/1000 (85%)\n",
            "\n",
            "Train Epoch: 20 [0/1000 (0%)]\tLosses 0: 0.006497\n",
            "Train Epoch: 20 [500/1000 (50%)]\tLosses 0: 0.003996\n",
            "Train Epoch: 20 [1000/1000 (100%)]\tLosses 0: 0.005971\n",
            "Test set:\n",
            "0: Loss: 0.6768\tAccuracy: 857/1000 (86%)\n",
            "\n",
            "Train Epoch: 21 [0/1000 (0%)]\tLosses 0: 0.004775\n",
            "Train Epoch: 21 [500/1000 (50%)]\tLosses 0: 0.003233\n",
            "Train Epoch: 21 [1000/1000 (100%)]\tLosses 0: 0.013093\n",
            "Test set:\n",
            "0: Loss: 0.6684\tAccuracy: 861/1000 (86%)\n",
            "\n",
            "Train Epoch: 22 [0/1000 (0%)]\tLosses 0: 0.002445\n",
            "Train Epoch: 22 [500/1000 (50%)]\tLosses 0: 0.003179\n",
            "Train Epoch: 22 [1000/1000 (100%)]\tLosses 0: 0.003400\n",
            "Test set:\n",
            "0: Loss: 0.6837\tAccuracy: 862/1000 (86%)\n",
            "\n",
            "Train Epoch: 23 [0/1000 (0%)]\tLosses 0: 0.005910\n",
            "Train Epoch: 23 [500/1000 (50%)]\tLosses 0: 0.002853\n",
            "Train Epoch: 23 [1000/1000 (100%)]\tLosses 0: 0.002726\n",
            "Test set:\n",
            "0: Loss: 0.6974\tAccuracy: 862/1000 (86%)\n",
            "\n",
            "Train Epoch: 24 [0/1000 (0%)]\tLosses 0: 0.035270\n",
            "Train Epoch: 24 [500/1000 (50%)]\tLosses 0: 0.004201\n",
            "Train Epoch: 24 [1000/1000 (100%)]\tLosses 0: 0.002853\n",
            "Test set:\n",
            "0: Loss: 0.7023\tAccuracy: 861/1000 (86%)\n",
            "\n",
            "Train Epoch: 25 [0/1000 (0%)]\tLosses 0: 0.002695\n",
            "Train Epoch: 25 [500/1000 (50%)]\tLosses 0: 0.002858\n",
            "Train Epoch: 25 [1000/1000 (100%)]\tLosses 0: 0.002390\n",
            "Test set:\n",
            "0: Loss: 0.7084\tAccuracy: 862/1000 (86%)\n",
            "\n",
            "Train Epoch: 26 [0/1000 (0%)]\tLosses 0: 0.001760\n",
            "Train Epoch: 26 [500/1000 (50%)]\tLosses 0: 0.002999\n",
            "Train Epoch: 26 [1000/1000 (100%)]\tLosses 0: 0.001718\n",
            "Test set:\n",
            "0: Loss: 0.7139\tAccuracy: 860/1000 (86%)\n",
            "\n",
            "Train Epoch: 27 [0/1000 (0%)]\tLosses 0: 0.001991\n",
            "Train Epoch: 27 [500/1000 (50%)]\tLosses 0: 0.002248\n",
            "Train Epoch: 27 [1000/1000 (100%)]\tLosses 0: 0.001836\n",
            "Test set:\n",
            "0: Loss: 0.7180\tAccuracy: 859/1000 (86%)\n",
            "\n",
            "Train Epoch: 28 [0/1000 (0%)]\tLosses 0: 0.002572\n",
            "Train Epoch: 28 [500/1000 (50%)]\tLosses 0: 0.001580\n",
            "Train Epoch: 28 [1000/1000 (100%)]\tLosses 0: 0.002112\n",
            "Test set:\n",
            "0: Loss: 0.7225\tAccuracy: 859/1000 (86%)\n",
            "\n",
            "Train Epoch: 29 [0/1000 (0%)]\tLosses 0: 0.001748\n",
            "Train Epoch: 29 [500/1000 (50%)]\tLosses 0: 0.001721\n",
            "Train Epoch: 29 [1000/1000 (100%)]\tLosses 0: 0.001869\n",
            "Test set:\n",
            "0: Loss: 0.7276\tAccuracy: 859/1000 (86%)\n",
            "\n",
            "Train Epoch: 30 [0/1000 (0%)]\tLosses 0: 0.001557\n",
            "Train Epoch: 30 [500/1000 (50%)]\tLosses 0: 0.000899\n",
            "Train Epoch: 30 [1000/1000 (100%)]\tLosses 0: 0.001798\n",
            "Test set:\n",
            "0: Loss: 0.7316\tAccuracy: 860/1000 (86%)\n",
            "\n",
            "Train Epoch: 31 [0/1000 (0%)]\tLosses 0: 0.001053\n",
            "Train Epoch: 31 [500/1000 (50%)]\tLosses 0: 0.001579\n",
            "Train Epoch: 31 [1000/1000 (100%)]\tLosses 0: 0.002106\n",
            "Test set:\n",
            "0: Loss: 0.7348\tAccuracy: 860/1000 (86%)\n",
            "\n",
            "Train Epoch: 32 [0/1000 (0%)]\tLosses 0: 0.001096\n",
            "Train Epoch: 32 [500/1000 (50%)]\tLosses 0: 0.001398\n",
            "Train Epoch: 32 [1000/1000 (100%)]\tLosses 0: 0.001295\n",
            "Test set:\n",
            "0: Loss: 0.7385\tAccuracy: 860/1000 (86%)\n",
            "\n",
            "Train Epoch: 33 [0/1000 (0%)]\tLosses 0: 0.001684\n",
            "Train Epoch: 33 [500/1000 (50%)]\tLosses 0: 0.002827\n",
            "Train Epoch: 33 [1000/1000 (100%)]\tLosses 0: 0.002060\n",
            "Test set:\n",
            "0: Loss: 0.7432\tAccuracy: 859/1000 (86%)\n",
            "\n",
            "Train Epoch: 34 [0/1000 (0%)]\tLosses 0: 0.001473\n",
            "Train Epoch: 34 [500/1000 (50%)]\tLosses 0: 0.001741\n",
            "Train Epoch: 34 [1000/1000 (100%)]\tLosses 0: 0.001090\n",
            "Test set:\n",
            "0: Loss: 0.7462\tAccuracy: 858/1000 (86%)\n",
            "\n",
            "Train Epoch: 35 [0/1000 (0%)]\tLosses 0: 0.003167\n",
            "Train Epoch: 35 [500/1000 (50%)]\tLosses 0: 0.001799\n",
            "Train Epoch: 35 [1000/1000 (100%)]\tLosses 0: 0.001265\n",
            "Test set:\n",
            "0: Loss: 0.7500\tAccuracy: 859/1000 (86%)\n",
            "\n",
            "Train Epoch: 36 [0/1000 (0%)]\tLosses 0: 0.001146\n",
            "Train Epoch: 36 [500/1000 (50%)]\tLosses 0: 0.001022\n",
            "Train Epoch: 36 [1000/1000 (100%)]\tLosses 0: 0.001413\n",
            "Test set:\n",
            "0: Loss: 0.7530\tAccuracy: 859/1000 (86%)\n",
            "\n",
            "Train Epoch: 37 [0/1000 (0%)]\tLosses 0: 0.001940\n",
            "Train Epoch: 37 [500/1000 (50%)]\tLosses 0: 0.001112\n",
            "Train Epoch: 37 [1000/1000 (100%)]\tLosses 0: 0.001105\n",
            "Test set:\n",
            "0: Loss: 0.7563\tAccuracy: 859/1000 (86%)\n",
            "\n",
            "Train Epoch: 38 [0/1000 (0%)]\tLosses 0: 0.002920\n",
            "Train Epoch: 38 [500/1000 (50%)]\tLosses 0: 0.000651\n",
            "Train Epoch: 38 [1000/1000 (100%)]\tLosses 0: 0.001183\n",
            "Test set:\n",
            "0: Loss: 0.7598\tAccuracy: 859/1000 (86%)\n",
            "\n",
            "Train Epoch: 39 [0/1000 (0%)]\tLosses 0: 0.001433\n",
            "Train Epoch: 39 [500/1000 (50%)]\tLosses 0: 0.001623\n",
            "Train Epoch: 39 [1000/1000 (100%)]\tLosses 0: 0.000785\n",
            "Test set:\n",
            "0: Loss: 0.7622\tAccuracy: 857/1000 (86%)\n",
            "\n",
            "Train Epoch: 40 [0/1000 (0%)]\tLosses 0: 0.003144\n",
            "Train Epoch: 40 [500/1000 (50%)]\tLosses 0: 0.001330\n",
            "Train Epoch: 40 [1000/1000 (100%)]\tLosses 0: 0.000937\n",
            "Test set:\n",
            "0: Loss: 0.7650\tAccuracy: 857/1000 (86%)\n",
            "\n",
            "Train Epoch: 41 [0/1000 (0%)]\tLosses 0: 0.000963\n",
            "Train Epoch: 41 [500/1000 (50%)]\tLosses 0: 0.001031\n",
            "Train Epoch: 41 [1000/1000 (100%)]\tLosses 0: 0.001145\n",
            "Test set:\n",
            "0: Loss: 0.7675\tAccuracy: 857/1000 (86%)\n",
            "\n",
            "Train Epoch: 42 [0/1000 (0%)]\tLosses 0: 0.001126\n",
            "Train Epoch: 42 [500/1000 (50%)]\tLosses 0: 0.001712\n",
            "Train Epoch: 42 [1000/1000 (100%)]\tLosses 0: 0.000750\n",
            "Test set:\n",
            "0: Loss: 0.7703\tAccuracy: 858/1000 (86%)\n",
            "\n",
            "Train Epoch: 43 [0/1000 (0%)]\tLosses 0: 0.000749\n",
            "Train Epoch: 43 [500/1000 (50%)]\tLosses 0: 0.001324\n",
            "Train Epoch: 43 [1000/1000 (100%)]\tLosses 0: 0.001398\n",
            "Test set:\n",
            "0: Loss: 0.7730\tAccuracy: 858/1000 (86%)\n",
            "\n",
            "Train Epoch: 44 [0/1000 (0%)]\tLosses 0: 0.000725\n",
            "Train Epoch: 44 [500/1000 (50%)]\tLosses 0: 0.000825\n",
            "Train Epoch: 44 [1000/1000 (100%)]\tLosses 0: 0.001016\n",
            "Test set:\n",
            "0: Loss: 0.7755\tAccuracy: 858/1000 (86%)\n",
            "\n",
            "Train Epoch: 45 [0/1000 (0%)]\tLosses 0: 0.000764\n",
            "Train Epoch: 45 [500/1000 (50%)]\tLosses 0: 0.001230\n",
            "Train Epoch: 45 [1000/1000 (100%)]\tLosses 0: 0.001383\n",
            "Test set:\n",
            "0: Loss: 0.7777\tAccuracy: 858/1000 (86%)\n",
            "\n",
            "Train Epoch: 46 [0/1000 (0%)]\tLosses 0: 0.001931\n",
            "Train Epoch: 46 [500/1000 (50%)]\tLosses 0: 0.001302\n",
            "Train Epoch: 46 [1000/1000 (100%)]\tLosses 0: 0.000958\n",
            "Test set:\n",
            "0: Loss: 0.7798\tAccuracy: 858/1000 (86%)\n",
            "\n",
            "Train Epoch: 47 [0/1000 (0%)]\tLosses 0: 0.001181\n",
            "Train Epoch: 47 [500/1000 (50%)]\tLosses 0: 0.001068\n",
            "Train Epoch: 47 [1000/1000 (100%)]\tLosses 0: 0.002118\n",
            "Test set:\n",
            "0: Loss: 0.7821\tAccuracy: 857/1000 (86%)\n",
            "\n",
            "Train Epoch: 48 [0/1000 (0%)]\tLosses 0: 0.000614\n",
            "Train Epoch: 48 [500/1000 (50%)]\tLosses 0: 0.000617\n",
            "Train Epoch: 48 [1000/1000 (100%)]\tLosses 0: 0.000979\n",
            "Test set:\n",
            "0: Loss: 0.7847\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 49 [0/1000 (0%)]\tLosses 0: 0.000809\n",
            "Train Epoch: 49 [500/1000 (50%)]\tLosses 0: 0.001072\n",
            "Train Epoch: 49 [1000/1000 (100%)]\tLosses 0: 0.000857\n",
            "Test set:\n",
            "0: Loss: 0.7870\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 50 [0/1000 (0%)]\tLosses 0: 0.000528\n",
            "Train Epoch: 50 [500/1000 (50%)]\tLosses 0: 0.000652\n",
            "Train Epoch: 50 [1000/1000 (100%)]\tLosses 0: 0.000839\n",
            "Test set:\n",
            "0: Loss: 0.7890\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 51 [0/1000 (0%)]\tLosses 0: 0.000884\n",
            "Train Epoch: 51 [500/1000 (50%)]\tLosses 0: 0.000863\n",
            "Train Epoch: 51 [1000/1000 (100%)]\tLosses 0: 0.000639\n",
            "Test set:\n",
            "0: Loss: 0.7912\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 52 [0/1000 (0%)]\tLosses 0: 0.001005\n",
            "Train Epoch: 52 [500/1000 (50%)]\tLosses 0: 0.000598\n",
            "Train Epoch: 52 [1000/1000 (100%)]\tLosses 0: 0.000812\n",
            "Test set:\n",
            "0: Loss: 0.7934\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 53 [0/1000 (0%)]\tLosses 0: 0.000681\n",
            "Train Epoch: 53 [500/1000 (50%)]\tLosses 0: 0.000577\n",
            "Train Epoch: 53 [1000/1000 (100%)]\tLosses 0: 0.001263\n",
            "Test set:\n",
            "0: Loss: 0.7954\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 54 [0/1000 (0%)]\tLosses 0: 0.000490\n",
            "Train Epoch: 54 [500/1000 (50%)]\tLosses 0: 0.000742\n",
            "Train Epoch: 54 [1000/1000 (100%)]\tLosses 0: 0.000561\n",
            "Test set:\n",
            "0: Loss: 0.7975\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 55 [0/1000 (0%)]\tLosses 0: 0.000607\n",
            "Train Epoch: 55 [500/1000 (50%)]\tLosses 0: 0.000564\n",
            "Train Epoch: 55 [1000/1000 (100%)]\tLosses 0: 0.000822\n",
            "Test set:\n",
            "0: Loss: 0.7995\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 56 [0/1000 (0%)]\tLosses 0: 0.000682\n",
            "Train Epoch: 56 [500/1000 (50%)]\tLosses 0: 0.000738\n",
            "Train Epoch: 56 [1000/1000 (100%)]\tLosses 0: 0.000863\n",
            "Test set:\n",
            "0: Loss: 0.8014\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 57 [0/1000 (0%)]\tLosses 0: 0.000459\n",
            "Train Epoch: 57 [500/1000 (50%)]\tLosses 0: 0.000910\n",
            "Train Epoch: 57 [1000/1000 (100%)]\tLosses 0: 0.000529\n",
            "Test set:\n",
            "0: Loss: 0.8032\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 58 [0/1000 (0%)]\tLosses 0: 0.000535\n",
            "Train Epoch: 58 [500/1000 (50%)]\tLosses 0: 0.000553\n",
            "Train Epoch: 58 [1000/1000 (100%)]\tLosses 0: 0.000446\n",
            "Test set:\n",
            "0: Loss: 0.8051\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 59 [0/1000 (0%)]\tLosses 0: 0.000541\n",
            "Train Epoch: 59 [500/1000 (50%)]\tLosses 0: 0.000831\n",
            "Train Epoch: 59 [1000/1000 (100%)]\tLosses 0: 0.000709\n",
            "Test set:\n",
            "0: Loss: 0.8071\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 60 [0/1000 (0%)]\tLosses 0: 0.000476\n",
            "Train Epoch: 60 [500/1000 (50%)]\tLosses 0: 0.000761\n",
            "Train Epoch: 60 [1000/1000 (100%)]\tLosses 0: 0.000564\n",
            "Test set:\n",
            "0: Loss: 0.8089\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 61 [0/1000 (0%)]\tLosses 0: 0.000785\n",
            "Train Epoch: 61 [500/1000 (50%)]\tLosses 0: 0.000729\n",
            "Train Epoch: 61 [1000/1000 (100%)]\tLosses 0: 0.000924\n",
            "Test set:\n",
            "0: Loss: 0.8106\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 62 [0/1000 (0%)]\tLosses 0: 0.000382\n",
            "Train Epoch: 62 [500/1000 (50%)]\tLosses 0: 0.000577\n",
            "Train Epoch: 62 [1000/1000 (100%)]\tLosses 0: 0.000537\n",
            "Test set:\n",
            "0: Loss: 0.8123\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 63 [0/1000 (0%)]\tLosses 0: 0.000517\n",
            "Train Epoch: 63 [500/1000 (50%)]\tLosses 0: 0.000430\n",
            "Train Epoch: 63 [1000/1000 (100%)]\tLosses 0: 0.000589\n",
            "Test set:\n",
            "0: Loss: 0.8139\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 64 [0/1000 (0%)]\tLosses 0: 0.000536\n",
            "Train Epoch: 64 [500/1000 (50%)]\tLosses 0: 0.001604\n",
            "Train Epoch: 64 [1000/1000 (100%)]\tLosses 0: 0.000558\n",
            "Test set:\n",
            "0: Loss: 0.8156\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 65 [0/1000 (0%)]\tLosses 0: 0.001020\n",
            "Train Epoch: 65 [500/1000 (50%)]\tLosses 0: 0.000467\n",
            "Train Epoch: 65 [1000/1000 (100%)]\tLosses 0: 0.000510\n",
            "Test set:\n",
            "0: Loss: 0.8171\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 66 [0/1000 (0%)]\tLosses 0: 0.000714\n",
            "Train Epoch: 66 [500/1000 (50%)]\tLosses 0: 0.000748\n",
            "Train Epoch: 66 [1000/1000 (100%)]\tLosses 0: 0.000435\n",
            "Test set:\n",
            "0: Loss: 0.8187\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 67 [0/1000 (0%)]\tLosses 0: 0.000423\n",
            "Train Epoch: 67 [500/1000 (50%)]\tLosses 0: 0.000568\n",
            "Train Epoch: 67 [1000/1000 (100%)]\tLosses 0: 0.000590\n",
            "Test set:\n",
            "0: Loss: 0.8204\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 68 [0/1000 (0%)]\tLosses 0: 0.000471\n",
            "Train Epoch: 68 [500/1000 (50%)]\tLosses 0: 0.000564\n",
            "Train Epoch: 68 [1000/1000 (100%)]\tLosses 0: 0.000591\n",
            "Test set:\n",
            "0: Loss: 0.8218\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 69 [0/1000 (0%)]\tLosses 0: 0.000649\n",
            "Train Epoch: 69 [500/1000 (50%)]\tLosses 0: 0.000310\n",
            "Train Epoch: 69 [1000/1000 (100%)]\tLosses 0: 0.000374\n",
            "Test set:\n",
            "0: Loss: 0.8234\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 70 [0/1000 (0%)]\tLosses 0: 0.000497\n",
            "Train Epoch: 70 [500/1000 (50%)]\tLosses 0: 0.000488\n",
            "Train Epoch: 70 [1000/1000 (100%)]\tLosses 0: 0.000701\n",
            "Test set:\n",
            "0: Loss: 0.8250\tAccuracy: 856/1000 (86%)\n",
            "\n",
            "Train Epoch: 71 [0/1000 (0%)]\tLosses 0: 0.000337\n",
            "Train Epoch: 71 [500/1000 (50%)]\tLosses 0: 0.000389\n",
            "Train Epoch: 71 [1000/1000 (100%)]\tLosses 0: 0.000434\n",
            "Test set:\n",
            "0: Loss: 0.8265\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 72 [0/1000 (0%)]\tLosses 0: 0.000675\n",
            "Train Epoch: 72 [500/1000 (50%)]\tLosses 0: 0.000413\n",
            "Train Epoch: 72 [1000/1000 (100%)]\tLosses 0: 0.001099\n",
            "Test set:\n",
            "0: Loss: 0.8279\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 73 [0/1000 (0%)]\tLosses 0: 0.000483\n",
            "Train Epoch: 73 [500/1000 (50%)]\tLosses 0: 0.000369\n",
            "Train Epoch: 73 [1000/1000 (100%)]\tLosses 0: 0.000326\n",
            "Test set:\n",
            "0: Loss: 0.8293\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 74 [0/1000 (0%)]\tLosses 0: 0.000401\n",
            "Train Epoch: 74 [500/1000 (50%)]\tLosses 0: 0.000436\n",
            "Train Epoch: 74 [1000/1000 (100%)]\tLosses 0: 0.000348\n",
            "Test set:\n",
            "0: Loss: 0.8308\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 75 [0/1000 (0%)]\tLosses 0: 0.000506\n",
            "Train Epoch: 75 [500/1000 (50%)]\tLosses 0: 0.000310\n",
            "Train Epoch: 75 [1000/1000 (100%)]\tLosses 0: 0.000449\n",
            "Test set:\n",
            "0: Loss: 0.8321\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 76 [0/1000 (0%)]\tLosses 0: 0.000409\n",
            "Train Epoch: 76 [500/1000 (50%)]\tLosses 0: 0.000364\n",
            "Train Epoch: 76 [1000/1000 (100%)]\tLosses 0: 0.000541\n",
            "Test set:\n",
            "0: Loss: 0.8335\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 77 [0/1000 (0%)]\tLosses 0: 0.000725\n",
            "Train Epoch: 77 [500/1000 (50%)]\tLosses 0: 0.000479\n",
            "Train Epoch: 77 [1000/1000 (100%)]\tLosses 0: 0.000453\n",
            "Test set:\n",
            "0: Loss: 0.8349\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 78 [0/1000 (0%)]\tLosses 0: 0.000369\n",
            "Train Epoch: 78 [500/1000 (50%)]\tLosses 0: 0.000416\n",
            "Train Epoch: 78 [1000/1000 (100%)]\tLosses 0: 0.000294\n",
            "Test set:\n",
            "0: Loss: 0.8363\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 79 [0/1000 (0%)]\tLosses 0: 0.000368\n",
            "Train Epoch: 79 [500/1000 (50%)]\tLosses 0: 0.000487\n",
            "Train Epoch: 79 [1000/1000 (100%)]\tLosses 0: 0.000463\n",
            "Test set:\n",
            "0: Loss: 0.8376\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 80 [0/1000 (0%)]\tLosses 0: 0.000951\n",
            "Train Epoch: 80 [500/1000 (50%)]\tLosses 0: 0.000670\n",
            "Train Epoch: 80 [1000/1000 (100%)]\tLosses 0: 0.000350\n",
            "Test set:\n",
            "0: Loss: 0.8389\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 81 [0/1000 (0%)]\tLosses 0: 0.000374\n",
            "Train Epoch: 81 [500/1000 (50%)]\tLosses 0: 0.000413\n",
            "Train Epoch: 81 [1000/1000 (100%)]\tLosses 0: 0.000445\n",
            "Test set:\n",
            "0: Loss: 0.8402\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 82 [0/1000 (0%)]\tLosses 0: 0.000408\n",
            "Train Epoch: 82 [500/1000 (50%)]\tLosses 0: 0.000507\n",
            "Train Epoch: 82 [1000/1000 (100%)]\tLosses 0: 0.000317\n",
            "Test set:\n",
            "0: Loss: 0.8415\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 83 [0/1000 (0%)]\tLosses 0: 0.000486\n",
            "Train Epoch: 83 [500/1000 (50%)]\tLosses 0: 0.000378\n",
            "Train Epoch: 83 [1000/1000 (100%)]\tLosses 0: 0.000558\n",
            "Test set:\n",
            "0: Loss: 0.8428\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 84 [0/1000 (0%)]\tLosses 0: 0.000317\n",
            "Train Epoch: 84 [500/1000 (50%)]\tLosses 0: 0.000844\n",
            "Train Epoch: 84 [1000/1000 (100%)]\tLosses 0: 0.000434\n",
            "Test set:\n",
            "0: Loss: 0.8440\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 85 [0/1000 (0%)]\tLosses 0: 0.000647\n",
            "Train Epoch: 85 [500/1000 (50%)]\tLosses 0: 0.000497\n",
            "Train Epoch: 85 [1000/1000 (100%)]\tLosses 0: 0.000392\n",
            "Test set:\n",
            "0: Loss: 0.8452\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 86 [0/1000 (0%)]\tLosses 0: 0.000435\n",
            "Train Epoch: 86 [500/1000 (50%)]\tLosses 0: 0.000224\n",
            "Train Epoch: 86 [1000/1000 (100%)]\tLosses 0: 0.000308\n",
            "Test set:\n",
            "0: Loss: 0.8464\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 87 [0/1000 (0%)]\tLosses 0: 0.000318\n",
            "Train Epoch: 87 [500/1000 (50%)]\tLosses 0: 0.000402\n",
            "Train Epoch: 87 [1000/1000 (100%)]\tLosses 0: 0.000467\n",
            "Test set:\n",
            "0: Loss: 0.8476\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 88 [0/1000 (0%)]\tLosses 0: 0.000423\n",
            "Train Epoch: 88 [500/1000 (50%)]\tLosses 0: 0.000356\n",
            "Train Epoch: 88 [1000/1000 (100%)]\tLosses 0: 0.000373\n",
            "Test set:\n",
            "0: Loss: 0.8488\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 89 [0/1000 (0%)]\tLosses 0: 0.000237\n",
            "Train Epoch: 89 [500/1000 (50%)]\tLosses 0: 0.000349\n",
            "Train Epoch: 89 [1000/1000 (100%)]\tLosses 0: 0.000248\n",
            "Test set:\n",
            "0: Loss: 0.8500\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 90 [0/1000 (0%)]\tLosses 0: 0.000265\n",
            "Train Epoch: 90 [500/1000 (50%)]\tLosses 0: 0.000362\n",
            "Train Epoch: 90 [1000/1000 (100%)]\tLosses 0: 0.000375\n",
            "Test set:\n",
            "0: Loss: 0.8511\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 91 [0/1000 (0%)]\tLosses 0: 0.000253\n",
            "Train Epoch: 91 [500/1000 (50%)]\tLosses 0: 0.000333\n",
            "Train Epoch: 91 [1000/1000 (100%)]\tLosses 0: 0.000305\n",
            "Test set:\n",
            "0: Loss: 0.8522\tAccuracy: 855/1000 (86%)\n",
            "\n",
            "Train Epoch: 92 [0/1000 (0%)]\tLosses 0: 0.000801\n",
            "Train Epoch: 92 [500/1000 (50%)]\tLosses 0: 0.000359\n",
            "Train Epoch: 92 [1000/1000 (100%)]\tLosses 0: 0.000319\n",
            "Test set:\n",
            "0: Loss: 0.8533\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 93 [0/1000 (0%)]\tLosses 0: 0.000260\n",
            "Train Epoch: 93 [500/1000 (50%)]\tLosses 0: 0.000309\n",
            "Train Epoch: 93 [1000/1000 (100%)]\tLosses 0: 0.000414\n",
            "Test set:\n",
            "0: Loss: 0.8544\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 94 [0/1000 (0%)]\tLosses 0: 0.000419\n",
            "Train Epoch: 94 [500/1000 (50%)]\tLosses 0: 0.000368\n",
            "Train Epoch: 94 [1000/1000 (100%)]\tLosses 0: 0.000502\n",
            "Test set:\n",
            "0: Loss: 0.8556\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 95 [0/1000 (0%)]\tLosses 0: 0.000288\n",
            "Train Epoch: 95 [500/1000 (50%)]\tLosses 0: 0.000377\n",
            "Train Epoch: 95 [1000/1000 (100%)]\tLosses 0: 0.000387\n",
            "Test set:\n",
            "0: Loss: 0.8566\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 96 [0/1000 (0%)]\tLosses 0: 0.000340\n",
            "Train Epoch: 96 [500/1000 (50%)]\tLosses 0: 0.000327\n",
            "Train Epoch: 96 [1000/1000 (100%)]\tLosses 0: 0.000308\n",
            "Test set:\n",
            "0: Loss: 0.8577\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 97 [0/1000 (0%)]\tLosses 0: 0.000274\n",
            "Train Epoch: 97 [500/1000 (50%)]\tLosses 0: 0.000443\n",
            "Train Epoch: 97 [1000/1000 (100%)]\tLosses 0: 0.000321\n",
            "Test set:\n",
            "0: Loss: 0.8587\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 98 [0/1000 (0%)]\tLosses 0: 0.000296\n",
            "Train Epoch: 98 [500/1000 (50%)]\tLosses 0: 0.000262\n",
            "Train Epoch: 98 [1000/1000 (100%)]\tLosses 0: 0.000184\n",
            "Test set:\n",
            "0: Loss: 0.8598\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 99 [0/1000 (0%)]\tLosses 0: 0.000329\n",
            "Train Epoch: 99 [500/1000 (50%)]\tLosses 0: 0.000374\n",
            "Train Epoch: 99 [1000/1000 (100%)]\tLosses 0: 0.000251\n",
            "Test set:\n",
            "0: Loss: 0.8608\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 100 [0/1000 (0%)]\tLosses 0: 0.000396\n",
            "Train Epoch: 100 [500/1000 (50%)]\tLosses 0: 0.000363\n",
            "Train Epoch: 100 [1000/1000 (100%)]\tLosses 0: 0.000239\n",
            "Test set:\n",
            "0: Loss: 0.8618\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 101 [0/1000 (0%)]\tLosses 0: 0.000249\n",
            "Train Epoch: 101 [500/1000 (50%)]\tLosses 0: 0.000372\n",
            "Train Epoch: 101 [1000/1000 (100%)]\tLosses 0: 0.000279\n",
            "Test set:\n",
            "0: Loss: 0.8627\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 102 [0/1000 (0%)]\tLosses 0: 0.000264\n",
            "Train Epoch: 102 [500/1000 (50%)]\tLosses 0: 0.000675\n",
            "Train Epoch: 102 [1000/1000 (100%)]\tLosses 0: 0.000416\n",
            "Test set:\n",
            "0: Loss: 0.8637\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 103 [0/1000 (0%)]\tLosses 0: 0.000203\n",
            "Train Epoch: 103 [500/1000 (50%)]\tLosses 0: 0.000179\n",
            "Train Epoch: 103 [1000/1000 (100%)]\tLosses 0: 0.000208\n",
            "Test set:\n",
            "0: Loss: 0.8647\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 104 [0/1000 (0%)]\tLosses 0: 0.000264\n",
            "Train Epoch: 104 [500/1000 (50%)]\tLosses 0: 0.000281\n",
            "Train Epoch: 104 [1000/1000 (100%)]\tLosses 0: 0.000371\n",
            "Test set:\n",
            "0: Loss: 0.8657\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 105 [0/1000 (0%)]\tLosses 0: 0.000444\n",
            "Train Epoch: 105 [500/1000 (50%)]\tLosses 0: 0.000293\n",
            "Train Epoch: 105 [1000/1000 (100%)]\tLosses 0: 0.000162\n",
            "Test set:\n",
            "0: Loss: 0.8666\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 106 [0/1000 (0%)]\tLosses 0: 0.000294\n",
            "Train Epoch: 106 [500/1000 (50%)]\tLosses 0: 0.000362\n",
            "Train Epoch: 106 [1000/1000 (100%)]\tLosses 0: 0.000330\n",
            "Test set:\n",
            "0: Loss: 0.8675\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 107 [0/1000 (0%)]\tLosses 0: 0.000238\n",
            "Train Epoch: 107 [500/1000 (50%)]\tLosses 0: 0.000341\n",
            "Train Epoch: 107 [1000/1000 (100%)]\tLosses 0: 0.000238\n",
            "Test set:\n",
            "0: Loss: 0.8685\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 108 [0/1000 (0%)]\tLosses 0: 0.000289\n",
            "Train Epoch: 108 [500/1000 (50%)]\tLosses 0: 0.000238\n",
            "Train Epoch: 108 [1000/1000 (100%)]\tLosses 0: 0.000275\n",
            "Test set:\n",
            "0: Loss: 0.8694\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 109 [0/1000 (0%)]\tLosses 0: 0.000360\n",
            "Train Epoch: 109 [500/1000 (50%)]\tLosses 0: 0.000294\n",
            "Train Epoch: 109 [1000/1000 (100%)]\tLosses 0: 0.000308\n",
            "Test set:\n",
            "0: Loss: 0.8703\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 110 [0/1000 (0%)]\tLosses 0: 0.000295\n",
            "Train Epoch: 110 [500/1000 (50%)]\tLosses 0: 0.000206\n",
            "Train Epoch: 110 [1000/1000 (100%)]\tLosses 0: 0.000494\n",
            "Test set:\n",
            "0: Loss: 0.8712\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 111 [0/1000 (0%)]\tLosses 0: 0.000225\n",
            "Train Epoch: 111 [500/1000 (50%)]\tLosses 0: 0.000712\n",
            "Train Epoch: 111 [1000/1000 (100%)]\tLosses 0: 0.000281\n",
            "Test set:\n",
            "0: Loss: 0.8721\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 112 [0/1000 (0%)]\tLosses 0: 0.000253\n",
            "Train Epoch: 112 [500/1000 (50%)]\tLosses 0: 0.000318\n",
            "Train Epoch: 112 [1000/1000 (100%)]\tLosses 0: 0.000337\n",
            "Test set:\n",
            "0: Loss: 0.8730\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 113 [0/1000 (0%)]\tLosses 0: 0.000311\n",
            "Train Epoch: 113 [500/1000 (50%)]\tLosses 0: 0.000171\n",
            "Train Epoch: 113 [1000/1000 (100%)]\tLosses 0: 0.000261\n",
            "Test set:\n",
            "0: Loss: 0.8739\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 114 [0/1000 (0%)]\tLosses 0: 0.000148\n",
            "Train Epoch: 114 [500/1000 (50%)]\tLosses 0: 0.000244\n",
            "Train Epoch: 114 [1000/1000 (100%)]\tLosses 0: 0.000203\n",
            "Test set:\n",
            "0: Loss: 0.8748\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 115 [0/1000 (0%)]\tLosses 0: 0.000314\n",
            "Train Epoch: 115 [500/1000 (50%)]\tLosses 0: 0.000330\n",
            "Train Epoch: 115 [1000/1000 (100%)]\tLosses 0: 0.000357\n",
            "Test set:\n",
            "0: Loss: 0.8756\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 116 [0/1000 (0%)]\tLosses 0: 0.000189\n",
            "Train Epoch: 116 [500/1000 (50%)]\tLosses 0: 0.000574\n",
            "Train Epoch: 116 [1000/1000 (100%)]\tLosses 0: 0.000182\n",
            "Test set:\n",
            "0: Loss: 0.8765\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 117 [0/1000 (0%)]\tLosses 0: 0.000167\n",
            "Train Epoch: 117 [500/1000 (50%)]\tLosses 0: 0.000382\n",
            "Train Epoch: 117 [1000/1000 (100%)]\tLosses 0: 0.000306\n",
            "Test set:\n",
            "0: Loss: 0.8773\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 118 [0/1000 (0%)]\tLosses 0: 0.000251\n",
            "Train Epoch: 118 [500/1000 (50%)]\tLosses 0: 0.000253\n",
            "Train Epoch: 118 [1000/1000 (100%)]\tLosses 0: 0.000246\n",
            "Test set:\n",
            "0: Loss: 0.8782\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 119 [0/1000 (0%)]\tLosses 0: 0.000143\n",
            "Train Epoch: 119 [500/1000 (50%)]\tLosses 0: 0.000307\n",
            "Train Epoch: 119 [1000/1000 (100%)]\tLosses 0: 0.000256\n",
            "Test set:\n",
            "0: Loss: 0.8790\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 120 [0/1000 (0%)]\tLosses 0: 0.000326\n",
            "Train Epoch: 120 [500/1000 (50%)]\tLosses 0: 0.000238\n",
            "Train Epoch: 120 [1000/1000 (100%)]\tLosses 0: 0.000573\n",
            "Test set:\n",
            "0: Loss: 0.8798\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 121 [0/1000 (0%)]\tLosses 0: 0.000362\n",
            "Train Epoch: 121 [500/1000 (50%)]\tLosses 0: 0.000323\n",
            "Train Epoch: 121 [1000/1000 (100%)]\tLosses 0: 0.000259\n",
            "Test set:\n",
            "0: Loss: 0.8807\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 122 [0/1000 (0%)]\tLosses 0: 0.000192\n",
            "Train Epoch: 122 [500/1000 (50%)]\tLosses 0: 0.000174\n",
            "Train Epoch: 122 [1000/1000 (100%)]\tLosses 0: 0.000349\n",
            "Test set:\n",
            "0: Loss: 0.8815\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 123 [0/1000 (0%)]\tLosses 0: 0.000515\n",
            "Train Epoch: 123 [500/1000 (50%)]\tLosses 0: 0.000259\n",
            "Train Epoch: 123 [1000/1000 (100%)]\tLosses 0: 0.000271\n",
            "Test set:\n",
            "0: Loss: 0.8822\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 124 [0/1000 (0%)]\tLosses 0: 0.000229\n",
            "Train Epoch: 124 [500/1000 (50%)]\tLosses 0: 0.000287\n",
            "Train Epoch: 124 [1000/1000 (100%)]\tLosses 0: 0.000285\n",
            "Test set:\n",
            "0: Loss: 0.8830\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 125 [0/1000 (0%)]\tLosses 0: 0.000164\n",
            "Train Epoch: 125 [500/1000 (50%)]\tLosses 0: 0.000217\n",
            "Train Epoch: 125 [1000/1000 (100%)]\tLosses 0: 0.000203\n",
            "Test set:\n",
            "0: Loss: 0.8838\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 126 [0/1000 (0%)]\tLosses 0: 0.000216\n",
            "Train Epoch: 126 [500/1000 (50%)]\tLosses 0: 0.000250\n",
            "Train Epoch: 126 [1000/1000 (100%)]\tLosses 0: 0.000243\n",
            "Test set:\n",
            "0: Loss: 0.8846\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 127 [0/1000 (0%)]\tLosses 0: 0.000184\n",
            "Train Epoch: 127 [500/1000 (50%)]\tLosses 0: 0.000226\n",
            "Train Epoch: 127 [1000/1000 (100%)]\tLosses 0: 0.000269\n",
            "Test set:\n",
            "0: Loss: 0.8854\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 128 [0/1000 (0%)]\tLosses 0: 0.000145\n",
            "Train Epoch: 128 [500/1000 (50%)]\tLosses 0: 0.000255\n",
            "Train Epoch: 128 [1000/1000 (100%)]\tLosses 0: 0.000311\n",
            "Test set:\n",
            "0: Loss: 0.8861\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 129 [0/1000 (0%)]\tLosses 0: 0.000314\n",
            "Train Epoch: 129 [500/1000 (50%)]\tLosses 0: 0.000307\n",
            "Train Epoch: 129 [1000/1000 (100%)]\tLosses 0: 0.000188\n",
            "Test set:\n",
            "0: Loss: 0.8869\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 130 [0/1000 (0%)]\tLosses 0: 0.000315\n",
            "Train Epoch: 130 [500/1000 (50%)]\tLosses 0: 0.000141\n",
            "Train Epoch: 130 [1000/1000 (100%)]\tLosses 0: 0.000265\n",
            "Test set:\n",
            "0: Loss: 0.8877\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 131 [0/1000 (0%)]\tLosses 0: 0.000212\n",
            "Train Epoch: 131 [500/1000 (50%)]\tLosses 0: 0.000273\n",
            "Train Epoch: 131 [1000/1000 (100%)]\tLosses 0: 0.000211\n",
            "Test set:\n",
            "0: Loss: 0.8884\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 132 [0/1000 (0%)]\tLosses 0: 0.000204\n",
            "Train Epoch: 132 [500/1000 (50%)]\tLosses 0: 0.000193\n",
            "Train Epoch: 132 [1000/1000 (100%)]\tLosses 0: 0.000252\n",
            "Test set:\n",
            "0: Loss: 0.8892\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 133 [0/1000 (0%)]\tLosses 0: 0.000163\n",
            "Train Epoch: 133 [500/1000 (50%)]\tLosses 0: 0.000379\n",
            "Train Epoch: 133 [1000/1000 (100%)]\tLosses 0: 0.000256\n",
            "Test set:\n",
            "0: Loss: 0.8899\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 134 [0/1000 (0%)]\tLosses 0: 0.000203\n",
            "Train Epoch: 134 [500/1000 (50%)]\tLosses 0: 0.000266\n",
            "Train Epoch: 134 [1000/1000 (100%)]\tLosses 0: 0.000264\n",
            "Test set:\n",
            "0: Loss: 0.8906\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 135 [0/1000 (0%)]\tLosses 0: 0.000151\n",
            "Train Epoch: 135 [500/1000 (50%)]\tLosses 0: 0.000228\n",
            "Train Epoch: 135 [1000/1000 (100%)]\tLosses 0: 0.000279\n",
            "Test set:\n",
            "0: Loss: 0.8913\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 136 [0/1000 (0%)]\tLosses 0: 0.000163\n",
            "Train Epoch: 136 [500/1000 (50%)]\tLosses 0: 0.000140\n",
            "Train Epoch: 136 [1000/1000 (100%)]\tLosses 0: 0.000239\n",
            "Test set:\n",
            "0: Loss: 0.8921\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 137 [0/1000 (0%)]\tLosses 0: 0.000244\n",
            "Train Epoch: 137 [500/1000 (50%)]\tLosses 0: 0.000361\n",
            "Train Epoch: 137 [1000/1000 (100%)]\tLosses 0: 0.000226\n",
            "Test set:\n",
            "0: Loss: 0.8928\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 138 [0/1000 (0%)]\tLosses 0: 0.001916\n",
            "Train Epoch: 138 [500/1000 (50%)]\tLosses 0: 0.000208\n",
            "Train Epoch: 138 [1000/1000 (100%)]\tLosses 0: 0.000085\n",
            "Test set:\n",
            "0: Loss: 0.8934\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 139 [0/1000 (0%)]\tLosses 0: 0.000241\n",
            "Train Epoch: 139 [500/1000 (50%)]\tLosses 0: 0.000270\n",
            "Train Epoch: 139 [1000/1000 (100%)]\tLosses 0: 0.000192\n",
            "Test set:\n",
            "0: Loss: 0.8942\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 140 [0/1000 (0%)]\tLosses 0: 0.000205\n",
            "Train Epoch: 140 [500/1000 (50%)]\tLosses 0: 0.000210\n",
            "Train Epoch: 140 [1000/1000 (100%)]\tLosses 0: 0.000148\n",
            "Test set:\n",
            "0: Loss: 0.8948\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 141 [0/1000 (0%)]\tLosses 0: 0.000400\n",
            "Train Epoch: 141 [500/1000 (50%)]\tLosses 0: 0.000240\n",
            "Train Epoch: 141 [1000/1000 (100%)]\tLosses 0: 0.000192\n",
            "Test set:\n",
            "0: Loss: 0.8955\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 142 [0/1000 (0%)]\tLosses 0: 0.000144\n",
            "Train Epoch: 142 [500/1000 (50%)]\tLosses 0: 0.000198\n",
            "Train Epoch: 142 [1000/1000 (100%)]\tLosses 0: 0.000313\n",
            "Test set:\n",
            "0: Loss: 0.8962\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 143 [0/1000 (0%)]\tLosses 0: 0.000189\n",
            "Train Epoch: 143 [500/1000 (50%)]\tLosses 0: 0.000132\n",
            "Train Epoch: 143 [1000/1000 (100%)]\tLosses 0: 0.000235\n",
            "Test set:\n",
            "0: Loss: 0.8969\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 144 [0/1000 (0%)]\tLosses 0: 0.000142\n",
            "Train Epoch: 144 [500/1000 (50%)]\tLosses 0: 0.000147\n",
            "Train Epoch: 144 [1000/1000 (100%)]\tLosses 0: 0.000165\n",
            "Test set:\n",
            "0: Loss: 0.8975\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 145 [0/1000 (0%)]\tLosses 0: 0.000210\n",
            "Train Epoch: 145 [500/1000 (50%)]\tLosses 0: 0.000223\n",
            "Train Epoch: 145 [1000/1000 (100%)]\tLosses 0: 0.000160\n",
            "Test set:\n",
            "0: Loss: 0.8982\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 146 [0/1000 (0%)]\tLosses 0: 0.000249\n",
            "Train Epoch: 146 [500/1000 (50%)]\tLosses 0: 0.000184\n",
            "Train Epoch: 146 [1000/1000 (100%)]\tLosses 0: 0.000163\n",
            "Test set:\n",
            "0: Loss: 0.8989\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 147 [0/1000 (0%)]\tLosses 0: 0.000146\n",
            "Train Epoch: 147 [500/1000 (50%)]\tLosses 0: 0.000155\n",
            "Train Epoch: 147 [1000/1000 (100%)]\tLosses 0: 0.000265\n",
            "Test set:\n",
            "0: Loss: 0.8996\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 148 [0/1000 (0%)]\tLosses 0: 0.000215\n",
            "Train Epoch: 148 [500/1000 (50%)]\tLosses 0: 0.000241\n",
            "Train Epoch: 148 [1000/1000 (100%)]\tLosses 0: 0.000124\n",
            "Test set:\n",
            "0: Loss: 0.9002\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 149 [0/1000 (0%)]\tLosses 0: 0.001599\n",
            "Train Epoch: 149 [500/1000 (50%)]\tLosses 0: 0.000224\n",
            "Train Epoch: 149 [1000/1000 (100%)]\tLosses 0: 0.000206\n",
            "Test set:\n",
            "0: Loss: 0.9008\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 150 [0/1000 (0%)]\tLosses 0: 0.000217\n",
            "Train Epoch: 150 [500/1000 (50%)]\tLosses 0: 0.000276\n",
            "Train Epoch: 150 [1000/1000 (100%)]\tLosses 0: 0.000180\n",
            "Test set:\n",
            "0: Loss: 0.9014\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 151 [0/1000 (0%)]\tLosses 0: 0.000377\n",
            "Train Epoch: 151 [500/1000 (50%)]\tLosses 0: 0.000243\n",
            "Train Epoch: 151 [1000/1000 (100%)]\tLosses 0: 0.000227\n",
            "Test set:\n",
            "0: Loss: 0.9021\tAccuracy: 854/1000 (85%)\n",
            "\n",
            "Train Epoch: 152 [0/1000 (0%)]\tLosses 0: 0.000146\n",
            "Train Epoch: 152 [500/1000 (50%)]\tLosses 0: 0.000275\n",
            "Train Epoch: 152 [1000/1000 (100%)]\tLosses 0: 0.000158\n",
            "Test set:\n",
            "0: Loss: 0.9027\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 153 [0/1000 (0%)]\tLosses 0: 0.000275\n",
            "Train Epoch: 153 [500/1000 (50%)]\tLosses 0: 0.000143\n",
            "Train Epoch: 153 [1000/1000 (100%)]\tLosses 0: 0.000166\n",
            "Test set:\n",
            "0: Loss: 0.9033\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 154 [0/1000 (0%)]\tLosses 0: 0.000204\n",
            "Train Epoch: 154 [500/1000 (50%)]\tLosses 0: 0.000261\n",
            "Train Epoch: 154 [1000/1000 (100%)]\tLosses 0: 0.000305\n",
            "Test set:\n",
            "0: Loss: 0.9040\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 155 [0/1000 (0%)]\tLosses 0: 0.000196\n",
            "Train Epoch: 155 [500/1000 (50%)]\tLosses 0: 0.000190\n",
            "Train Epoch: 155 [1000/1000 (100%)]\tLosses 0: 0.000152\n",
            "Test set:\n",
            "0: Loss: 0.9045\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 156 [0/1000 (0%)]\tLosses 0: 0.000224\n",
            "Train Epoch: 156 [500/1000 (50%)]\tLosses 0: 0.000424\n",
            "Train Epoch: 156 [1000/1000 (100%)]\tLosses 0: 0.000210\n",
            "Test set:\n",
            "0: Loss: 0.9051\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 157 [0/1000 (0%)]\tLosses 0: 0.000192\n",
            "Train Epoch: 157 [500/1000 (50%)]\tLosses 0: 0.000212\n",
            "Train Epoch: 157 [1000/1000 (100%)]\tLosses 0: 0.000204\n",
            "Test set:\n",
            "0: Loss: 0.9058\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 158 [0/1000 (0%)]\tLosses 0: 0.000178\n",
            "Train Epoch: 158 [500/1000 (50%)]\tLosses 0: 0.000219\n",
            "Train Epoch: 158 [1000/1000 (100%)]\tLosses 0: 0.000225\n",
            "Test set:\n",
            "0: Loss: 0.9064\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 159 [0/1000 (0%)]\tLosses 0: 0.000262\n",
            "Train Epoch: 159 [500/1000 (50%)]\tLosses 0: 0.000165\n",
            "Train Epoch: 159 [1000/1000 (100%)]\tLosses 0: 0.000152\n",
            "Test set:\n",
            "0: Loss: 0.9070\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 160 [0/1000 (0%)]\tLosses 0: 0.000151\n",
            "Train Epoch: 160 [500/1000 (50%)]\tLosses 0: 0.000107\n",
            "Train Epoch: 160 [1000/1000 (100%)]\tLosses 0: 0.000166\n",
            "Test set:\n",
            "0: Loss: 0.9076\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 161 [0/1000 (0%)]\tLosses 0: 0.000173\n",
            "Train Epoch: 161 [500/1000 (50%)]\tLosses 0: 0.000217\n",
            "Train Epoch: 161 [1000/1000 (100%)]\tLosses 0: 0.000161\n",
            "Test set:\n",
            "0: Loss: 0.9082\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 162 [0/1000 (0%)]\tLosses 0: 0.000172\n",
            "Train Epoch: 162 [500/1000 (50%)]\tLosses 0: 0.000175\n",
            "Train Epoch: 162 [1000/1000 (100%)]\tLosses 0: 0.000175\n",
            "Test set:\n",
            "0: Loss: 0.9088\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 163 [0/1000 (0%)]\tLosses 0: 0.000144\n",
            "Train Epoch: 163 [500/1000 (50%)]\tLosses 0: 0.000136\n",
            "Train Epoch: 163 [1000/1000 (100%)]\tLosses 0: 0.000194\n",
            "Test set:\n",
            "0: Loss: 0.9094\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 164 [0/1000 (0%)]\tLosses 0: 0.000175\n",
            "Train Epoch: 164 [500/1000 (50%)]\tLosses 0: 0.000200\n",
            "Train Epoch: 164 [1000/1000 (100%)]\tLosses 0: 0.000156\n",
            "Test set:\n",
            "0: Loss: 0.9100\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 165 [0/1000 (0%)]\tLosses 0: 0.000196\n",
            "Train Epoch: 165 [500/1000 (50%)]\tLosses 0: 0.000166\n",
            "Train Epoch: 165 [1000/1000 (100%)]\tLosses 0: 0.000261\n",
            "Test set:\n",
            "0: Loss: 0.9105\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 166 [0/1000 (0%)]\tLosses 0: 0.000225\n",
            "Train Epoch: 166 [500/1000 (50%)]\tLosses 0: 0.000210\n",
            "Train Epoch: 166 [1000/1000 (100%)]\tLosses 0: 0.000159\n",
            "Test set:\n",
            "0: Loss: 0.9111\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 167 [0/1000 (0%)]\tLosses 0: 0.000150\n",
            "Train Epoch: 167 [500/1000 (50%)]\tLosses 0: 0.000152\n",
            "Train Epoch: 167 [1000/1000 (100%)]\tLosses 0: 0.000131\n",
            "Test set:\n",
            "0: Loss: 0.9117\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 168 [0/1000 (0%)]\tLosses 0: 0.000131\n",
            "Train Epoch: 168 [500/1000 (50%)]\tLosses 0: 0.000228\n",
            "Train Epoch: 168 [1000/1000 (100%)]\tLosses 0: 0.000182\n",
            "Test set:\n",
            "0: Loss: 0.9122\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 169 [0/1000 (0%)]\tLosses 0: 0.000179\n",
            "Train Epoch: 169 [500/1000 (50%)]\tLosses 0: 0.000317\n",
            "Train Epoch: 169 [1000/1000 (100%)]\tLosses 0: 0.000181\n",
            "Test set:\n",
            "0: Loss: 0.9128\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 170 [0/1000 (0%)]\tLosses 0: 0.000222\n",
            "Train Epoch: 170 [500/1000 (50%)]\tLosses 0: 0.000136\n",
            "Train Epoch: 170 [1000/1000 (100%)]\tLosses 0: 0.000204\n",
            "Test set:\n",
            "0: Loss: 0.9134\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 171 [0/1000 (0%)]\tLosses 0: 0.000192\n",
            "Train Epoch: 171 [500/1000 (50%)]\tLosses 0: 0.000155\n",
            "Train Epoch: 171 [1000/1000 (100%)]\tLosses 0: 0.000195\n",
            "Test set:\n",
            "0: Loss: 0.9139\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 172 [0/1000 (0%)]\tLosses 0: 0.000103\n",
            "Train Epoch: 172 [500/1000 (50%)]\tLosses 0: 0.000152\n",
            "Train Epoch: 172 [1000/1000 (100%)]\tLosses 0: 0.000250\n",
            "Test set:\n",
            "0: Loss: 0.9145\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 173 [0/1000 (0%)]\tLosses 0: 0.000165\n",
            "Train Epoch: 173 [500/1000 (50%)]\tLosses 0: 0.000132\n",
            "Train Epoch: 173 [1000/1000 (100%)]\tLosses 0: 0.000146\n",
            "Test set:\n",
            "0: Loss: 0.9150\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 174 [0/1000 (0%)]\tLosses 0: 0.000139\n",
            "Train Epoch: 174 [500/1000 (50%)]\tLosses 0: 0.000445\n",
            "Train Epoch: 174 [1000/1000 (100%)]\tLosses 0: 0.000142\n",
            "Test set:\n",
            "0: Loss: 0.9155\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 175 [0/1000 (0%)]\tLosses 0: 0.000162\n",
            "Train Epoch: 175 [500/1000 (50%)]\tLosses 0: 0.000130\n",
            "Train Epoch: 175 [1000/1000 (100%)]\tLosses 0: 0.000157\n",
            "Test set:\n",
            "0: Loss: 0.9161\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 176 [0/1000 (0%)]\tLosses 0: 0.000189\n",
            "Train Epoch: 176 [500/1000 (50%)]\tLosses 0: 0.000153\n",
            "Train Epoch: 176 [1000/1000 (100%)]\tLosses 0: 0.000109\n",
            "Test set:\n",
            "0: Loss: 0.9167\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 177 [0/1000 (0%)]\tLosses 0: 0.000142\n",
            "Train Epoch: 177 [500/1000 (50%)]\tLosses 0: 0.000118\n",
            "Train Epoch: 177 [1000/1000 (100%)]\tLosses 0: 0.000160\n",
            "Test set:\n",
            "0: Loss: 0.9172\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 178 [0/1000 (0%)]\tLosses 0: 0.000169\n",
            "Train Epoch: 178 [500/1000 (50%)]\tLosses 0: 0.000173\n",
            "Train Epoch: 178 [1000/1000 (100%)]\tLosses 0: 0.000121\n",
            "Test set:\n",
            "0: Loss: 0.9177\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 179 [0/1000 (0%)]\tLosses 0: 0.000183\n",
            "Train Epoch: 179 [500/1000 (50%)]\tLosses 0: 0.000115\n",
            "Train Epoch: 179 [1000/1000 (100%)]\tLosses 0: 0.000121\n",
            "Test set:\n",
            "0: Loss: 0.9183\tAccuracy: 853/1000 (85%)\n",
            "\n",
            "Train Epoch: 180 [0/1000 (0%)]\tLosses 0: 0.000157\n",
            "Train Epoch: 180 [500/1000 (50%)]\tLosses 0: 0.000154\n",
            "Train Epoch: 180 [1000/1000 (100%)]\tLosses 0: 0.000218\n",
            "Test set:\n",
            "0: Loss: 0.9188\tAccuracy: 853/1000 (85%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18fF2IRYirpi",
        "colab_type": "code",
        "outputId": "46c9913c-90a9-48d3-d53e-5e4b9ddcb37d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# построение графиков\n",
        "plt.plot(train_loss_history, label = 'train_loss');\n",
        "plt.plot(test_loss_history, label = 'test_loss');\n",
        "plt.title('График переобучения');\n",
        "plt.xlabel('Количество эпох')\n",
        "plt.ylabel('log_loss')\n",
        "plt.grid();\n",
        "plt.legend();"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbRMQbvAqPAN",
        "colab_type": "code",
        "outputId": "d08d18e6-dd62-4ea8-aa59-c42818735cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# тоже самое для accuracy\n",
        "plt.plot(accuracy_train_history, label = 'train_accuracy');\n",
        "plt.plot(accuracy_test_history, label = 'test_accuracy');\n",
        "plt.title('График переобучения');\n",
        "plt.xlabel('Количество эпох')\n",
        "plt.ylabel('accuracy')\n",
        "plt.ylim(bottom = 0.84,top = 1.01)\n",
        "plt.grid();\n",
        "plt.legend();"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd5gV5fn/8feHpQmLVN1oqElQAWGVRUQRBQuiiajYC5FExNi++SbRBC/5WeM3RROj0RgxwRYN9sQkxIasvSAWFBFpShUQpCxL2XL//pjZ5XA4u5wts2dnz/26rnPtlGdm7p2Fuc/zPDPPyMxwzjnnkjXLdADOOecaJ08QzjnnUvIE4ZxzLiVPEM4551LyBOGccy4lTxDOxZwCzTMdh2t6PEE4F0OSRkh6VtISYCNweqZjck2PJwhXryR9LmmLpKKEz/+r52P0lGTZ+q1Z0hHAo8CdQC8za2dmUzMclmuCsvI/mIvcSWb2YqaDaMJ+CVxhZv/OdCCuafMahGswku6X9GdJL0jaJOllST0S1t8uaamkjZJmSRqWsK5j2KSyGrg8XHyjpDWSnpG0Z1huuKRlCdudGdY2xofz4yS9Fk43k/T38LPL/4WEmkpibahE0vUJZb4n6QNJ6yW9IWlAwrrPJV0t6RNJX0u6T1LrNLftI6kwXDdH0uiE0AYDIyV9KWmFpD9IahVu97GkkxL200LSV5IOTvzdk89FOH9A+LdZJ2mepDOT/na/TJj/jiRLmC9MOMfNJH2U9Hc4IvxdN4XnsVzS8ORz7hoXTxCuoZ0H3AR0AT4AHk5YNxM4COgEPAI8nnBBvQnYAPQAtobLVgLdgTLg+uQDSWoRbreyiljuBDoA3zez8mpi7mBmuWaWS9C0U7H/g4EpwMVAZ+Ae4JmKi3XC73s88G1gP2DS7rYN4/4X8DywN3AF8LCk/cN97gH0AwYA+QQJY1K47kHg/ITjnwisNLP3gXKq+D8vqS3wAsF53xs4G/iTpL7VnJeqXAB0TFp2K/A0sGd4HlfUYr+ugXmCcA3tP2b2ipltA64BDpPUDcDM/mZma82s1Mx+B7QCKi6KJwF3mdkW4C/hsrvD+duBMSmOdTHwNvBZ8gpJNwEjgNPMrKSWv8sE4B4ze9vMyszsAWAbMCShzJ1mttTM1gE3A+ekse0QIBf4tZltN7OXgH8nbAtwo5mtNrM1wA3A2HD534ATK2pU4fKHwuklQB9JXVP8Lt8DPjez+8Lz/z7wJHBGTU5ImNCvJUjMyXIA1WR/LrM8QbiGtrRiwsyKgHXAvgCSrpQ0V9IGSeuB9gQ1DYA8YE0V+1wNfCNxgaR2wM+BVB3kAwkSShfgW7X/VegB/CxsBlofxtyt4vcJLU2Y/iJhXXXb7gssTarVfAF8M5zeHs7vsl8zWwG8DpwmqQNwAjtqaS8T1IA+DI/3p6Tf5dCkeM5j5/N6ZcK696o4Jz8GngXmJS2/AhgNbA233zd5Q9f4eIJwDa1bxYSkXILmpBVhf8PPgTOBjmbWgaBJqeIb5xp2JItkewOrkpZdBTxmZl+kKL8BOJagBjNFUk4tf5elwM1m1iHh08bM/p5QplvCdHd2NK1Ut+0KoFtSv0h3YHk4vYTggp5qvwAPEDQznQG8aWbLASzwIzPrHJ7fS5N+l5eT4sk1s0sSytxasY4gySbrRNA/dEPyCjObSZDIrgm39yamGPAE4RraiWGHZUuCZoi3zGwp0A4oJUgEzSVdC+yZsN004FJJewDjw2WXhPP/Q9BmX6Ed8AOCJp1UFprZSjObTPAMwZW1/F3uBX4k6VAF2kr6blh7qXCZpK6SOhEkpEfT2PZtoBj4edjJPJygia3iVta/A5Mk7SWpC0GTzt8SjvkPggv4jwn6JNLxb2A/SWPDY7aQdIikPjU4H/8L/NXMvkxeEXZ4dwduq8H+XIZ5gnAN7RHgOoKmpQJ2dKg+R9A08RnBN82t7Nw8MwnYK1xX0Qn8jbBMa3ZuStoTuMPMvk4jnvEETSf777ZkEjN7F7iIoLP7a2ABMC6p2CMEnc2LgIUEt6hWu62ZbSdICCcAXxE0BX3fzD4N9/l/BE08H4Wf9yr2G26/haD/oBfwVJq/yyZgJEHn9ArgS+A37DjX6cgh6IzeiaSOBInhIjMrrcH+XIbJXxjkGoqk+4FlZjZpd2V3s5+ewGKgRWO+4Ej6HBifiWdCwhrYfmZ2/m4LO1cFf1DOuSYmbM66kB13NjlXK97E5FwTIukigma3/5rZK5mOx8WbNzE555xLyWsQzjnnUmoyfRBdunSxnj171nr7zZs307Zt2/oLKCJxiRPiE2tc4oT4xBqXOCE+sUYV56xZs74ys71SrjSzJvEpKCiwupgxY0adtm8ocYnTLD6xxiVOs/jEGpc4zeITa1RxAu9aFddVb2JyzjmXkicI55xzKXmCcM45l5InCOeccyl5gnDOOZeSJwjnnHMpeYJwzjmXkicI55xzKUWWICRNkbRa0sdVrJekOyQtkDRb0sCEdRdImh9+LogqRuecc1WLsgZxPzCqmvUnAL3DzwTgbqgcqvg64FBgMHBd+MIR55xzDSiysZjM7JXwxS5VORl4MHzU+y1JHSTtAwwHXjCzdQCSXiBINH+vck+N2MatJfzhhflsKSmrl/2tXLGN59Z9VC/7ilpcYo1LnBCfWOMSJ8Qn1uri7NZpDy4d/p16P2YmB+v7Jju/UnJZuKyq5buQNIGg9kFeXh6FhYW1DqaoqKhO21flnS9LmfLBNtq1gGbNVOf9WXk5WrN09wUbgbjEGpc4IT6xxiVOiE+s1cXZY89m9GVZvR8z1qO5WvDS+ckAgwYNsuHDh9d6X4WFhdRl+6rMLVwIfMqbk44nt1XdT3dUcUYhLrHGJU6IT6xxiRPiE2sm4szkXUzLgW4J813DZVUtj6Ul64rp3LZlvSQH55xrSJlMEM8A3w/vZhoCbDCzlcBzwEhJHcPO6ZHhslhauq6Ybp3aZDoM55yrsci+1kr6O0GHcxdJywjuTGoBYGZ/BqYBJwILgGLgB+G6dZJuAmaGu7qxosM6jpasK+agbh0yHYZzztVYlHcxnbOb9QZcVsW6KcCUKOJqSKVl5Sxfv4XR+ftmOhTnnKsxf5I6Qis3bKWs3OjuTUzOuRjyBBGhJeuKAbwPwjkXS54gIlSRILp39gThnIsfTxARWrKumBY54ht7ts50KM45V2OeICK0ZF0xXTu2IacenqB2zrmG5gkiQv4MhHMuzjxBRGjJumK6d9oj02E451yteIKIyIYtJawvLvFbXJ1zseUJIiJLK+5g8gThnIspTxAR8WcgnHNx5wkiIp4gnHNx5wkiIkvWFdOxTQv2bN0i06E451yteIKIyNJ1xd7/4JyLNU8QEVniz0A452LOE0QESsvKWf71Fq9BOOdizRNEBFZu2EqpD/PtnIs5TxAR8GcgnHNNQaQJQtIoSfMkLZA0McX6HpKmS5otqVBS14R1v5U0R9JcSXdIis2Id36Lq3OuKYgsQUjKAe4CTgD6AudI6ptU7FbgQTMbANwI/Crc9nBgKDAAOBA4BDgqqljrU2lZOZ+vLaZ5M7FPex/m2zkXX5G9kxoYDCwws0UAkqYCJwOfJJTpC/w0nJ4B/COcNqA10BIQ0AJYFWGs9eK1+V9xwX3vUFZu9OzchuY53oLnnIsvmVk0O5ZOB0aZ2fhwfixwqJldnlDmEeBtM7td0hjgSaCLma2VdCswniBB3Glm16Q4xgRgAkBeXl7B1KlTax1vUVERubm5td4e4J8LtvP0ghLG9G5B7w459OmcU6f9pVIfcTaUuMQalzghPrHGJU6IT6xRxTlixIhZZjYo5Uozi+QDnA78JWF+LMGFPrHMvsBTwPvA7cAyoAPwHeA/QG74eRMYVt3xCgoKrC5mzJhRp+3NzH722Ad26M0v1nk/1amPOBtKXGKNS5xm8Yk1LnGaxSfWqOIE3rUqrqtRNjEtB7olzHcNl1UysxXAGABJucBpZrZe0kXAW2ZWFK77L3AY8GqE8dbZEn962jnXhETZSD4T6C2pl6SWwNnAM4kFJHWRVBHD1cCUcHoJcJSk5pJaEHRQz40w1nrhb5BzzjUlkSUIMysFLgeeI7i4P2ZmcyTdKGl0WGw4ME/SZ0AecHO4/AlgIfAR8CHwoZn9K6pY68PWkjK+3LjVaxDOuSYjyiYmzGwaMC1p2bUJ008QJIPk7cqAi6OMrb4tX78FM+je2V8x6pxrGvw+zHqyxJ+eds41MZ4g6slSf3raOdfEeIKoJ0vWFtO6RTP2ym2V6VCcc65eeIKoJxW3uMZoyCjnnKuWJ4h64s9AOOeaGk8QdfT15u3M+mKdPwPhnGtyIr3NNRv86G+zeHvxOgC+s3fjH8/FOefS5QmijuavLuLYPnvzwyN6MahHp0yH45xz9cYTRB1s2lrCus3bKejRicO/3SXT4TjnXL3yPog6WLpuC+APxznnmiZPEHXgT08755oyTxB1sNQThHOuCfMEUQdL1hWzZ+vmtG/TItOhOOdcvfMEUQdL1hXTvbPXHpxzTZMniDpYuq6YHp3aZjoM55yLhCeIWiorN5Z9vcWfnnbONVmRJghJoyTNk7RA0sQU63tImi5ptqRCSV0T1nWX9LykuZI+kdQzylhratXGrWwvK/cOaudckxVZgpCUA9wFnAD0Bc6R1Dep2K3Ag2Y2ALgR+FXCugeBW8ysDzAYWB1VrLXht7g655q6KGsQg4EFZrbIzLYDU4GTk8r0BV4Kp2dUrA8TSXMzewHAzIrMrDjCWGvME4RzrqmTmUWzY+l0YJSZjQ/nxwKHmtnlCWUeAd42s9sljQGeBLoAw4DxwHagF/AiMDF8V3XiMSYAEwDy8vIKpk6dWut4i4qKyM1Nf7C9fy7YztMLSvjLyDY0b9Zw74CoaZyZFJdY4xInxCfWuMQJ8Yk1qjhHjBgxy8wGpVxpZpF8gNOBvyTMjwXuTCqzL/AU8D5wO7AM6BBuuwH4FsF4UU8CF1Z3vIKCAquLGTNm1Kj8b/4717599X/qdMzaqGmcmRSXWOMSp1l8Yo1LnGbxiTWqOIF3rYrrapRNTMuBbgnzXcNllcxshZmNMbODgWvCZevDRPGBBc1TpcA/gIERxlpjW0vKadXcbwJzzjVdUV7hZgK9JfWS1BI4G3gmsYCkLpIqYrgamJKwbQdJe4XzRwOfRBhrjW0rLaN1i5xMh+Gcc5GJLEGE3/wvB54D5gKPmdkcSTdKGh0WGw7Mk/QZkAfcHG5bBlwJTJf0ESDg3qhirQ2vQTjnmrpI3wdhZtOAaUnLrk2YfgJ4ooptXwAGRBlfXXgNwjnX1PlX4FraWlJOS69BOOeaML/C1ZLXIJxzTZ0niFra5n0Qzrkmzq9wteQ1COdcU+cJopb8LibnXFPnV7ha8hqEc66p8wRRS16DcM41dX6FqyWvQTjnmjpPELXkNQjnXFPnV7haMDOvQTjnmjxPELVQUmaUG16DcM41aX6Fq4VtpcF7i7wG4ZxryjxB1MLWknIAWrXw0+eca7r8ClcLlTWI5l6DcM41XZ4gasFrEM65bOBXuFqoqEG08hqEc64J8wRRCxU1iNZeg3DONWGRXuEkjZI0T9ICSRNTrO8habqk2ZIKJXVNWr+npGWS7owyzpryGoRzLhtEliAk5QB3AScAfYFzJPVNKnYr8KCZDQBuBH6VtP4m4JWoYqytbV6DcM5lgSivcIOBBWa2yMy2A1OBk5PK9AVeCqdnJK6XVADkAc9HGGOteA3COZcNZGa7LyQ9BfwV+K+Zlae1Y+l0YJSZjQ/nxwKHmtnlCWUeAd42s9sljQGeBLoAXxMkjvOBY4FBidslbD8BmACQl5dXMHXq1HRCS6moqIjc3Ny0yr6xopTJs7fx62F78I22DVuLqEmcmRaXWOMSJ8Qn1rjECfGJNao4R4wYMcvMBqVcaWa7/RBcpB8GFgK/BvZPY5vTgb8kzI8F7kwqsy/wFPA+cDuwDOgAXA78PCwzLnm7VJ+CggKrixkzZqRdduo7X1iPX/zbln1dXKdj1kZN4sy0uMQalzjN4hNrXOI0i0+sUcUJvGtVXFebp5NhzOxF4EVJ7YFzwumlwL3A38ysJMVmy4FuCfNdw2WJ+10BjAGQlAucZmbrJR0GDJN0KZALtJRUZGa7dHRnQuVdTD4Wk8tiJSUlLFu2jK1bt+6yrn379sydOzcDUdVcXGKta5ytW7ema9eutGjRIu1t0koQAJI6EzT5jCX4xv8wcARwATA8xSYzgd6SehEkhrOBc5P22QVYZ0Gz1dXAFAAzOy+hzDiCJqZGkRwgoQ/Cx2JyWWzZsmW0a9eOnj17ImmndZs2baJdu3YZiqxm4hJrXeI0M9auXcuyZcvo1atX2tul9RVY0tPAq0Ab4CQzG21mj5rZFQTf8FMFVErQVPQcMBd4zMzmSLpR0uiw2HBgnqTPCDqkb0478gzyGoRzsHXrVjp37rxLcnCNjyQ6d+6csrZXnXRrEHeY2YxUK6yqzo1g3TRgWtKyaxOmnwCeqO7AZnY/cH+acTaIbaVl5DQTzXM8Qbjs5skhPmrzt0r3CtdXUoeEA3UM+wey0taScq89OOeavHSvcheZ2fqKGTP7GrgompAav22lZd7/4Jxr8tJNEDlKqJ+ET0m3jCakxs9rEM5l3vr16/nTn/5U4+1OPPFE1q9fv/uCLu0+iGeBRyXdE85fHC7LSttKy70G4VyCG/41h09WbKycLysrIyenbv9H+u67J9ed1K/K9RUJ4tJLd27tLi0tpXnzqi9t06ZNq3JdY7C7+BtSul+Df0EwFMYl4Wc68POogmrstpaU+fuoncuwiRMnsnDhQg466CAOOeQQhg0bxujRo+nbNxjy7ZRTTqGgoIB+/foxefLkyu169uzJV199xeeff06fPn244oor6NevHyNHjmTLli1VHu/ee+/lkEMOIT8/n9NOO43i4mIAVq1axamnnkp+fj75+fm88cYbADz44IMMGDCA/Px8xo4dC8C4ceN44okd9+VUPBldWFiYdvzPPvssAwcOJD8/n2OOOYby8nJ69+7NmjVrACgvL+c73/lO5XydVPUEXdw+Dfkk9di/vm2j73ytTserrbg89WkWn1jjEqdZ44r1k08+qXLdxo0bIz/+4sWLrV+/fmYWnJc2bdrYokWLKtevXbvWzMyKi4utX79+9tVXX5mZWY8ePWzNmjW2ePFiy8nJsddeC/4vn3HGGfbQQw9VebyK7c3MrrnmGrvjjjvMzOzMM8+02267zczMSktLbf369fbxxx9b7969bc2aNTvFcsEFF9jjjz9euZ+2bdumHf/ixYtt9erV1rVr18pyFWWuv/76yhiee+45GzNmTMrfIdXfjGqepE73OYjekp6Q9ImkRRWfuqeneNpaUuZ9EM41MoMHD97pIbA77riD/Px8hgwZwtKlS5k/f/4u2/Tq1YsBAwYAUFBQwOeff17l/j/++GOGDRtG//79efjhh5kzZw4AL730EpdccgkAOTk5tG/fnpdeeokzzjiDLl26ANCpU6c6x79w4ULeeustjjzyyMpyFfv94Q9/yIMPPgjAlClT+MEPfrDb46Uj3Yau+4DrgNuAEcAPyOKXDW0rLaf9Huk/ru6ci17btm0rpwsLC3nxxRd58803adOmDcOHD0/5kFirVq0qp3NycqptYho3bhz/+Mc/yM/P5/7776ewsLDGMTZv3pzy8uBB2/LycrZv3552/Nu2batyv926dSMvL4+XXnqJd955h4cffrjGsaWS7kV+DzObTjD66xdmdj3w3XqJIIa2eQ3CuYxr164dmzZtSrluw4YNdOzYkTZt2vDpp5/y1ltv1fl4mzZtYp999qGkpGSnC/AxxxzD3XffDQSd8xs2bODoo4/m8ccfZ+3atQCsW7cOCPo/Zs2aBcAzzzxDSUmqYeyqjn/IkCG88sorLF68eKf9AowfP57zzz+fM844o843CFRI9yq3TVIzYL6kyyWdShVDbGQDv4vJuczr3LkzQ4cO5cADD+Sqq67aad2oUaMoLS2lT58+TJw4kSFDhtT5eDfddBOHHnooQ4cO5YADDqhcfvvttzNjxgz69+9PQUEBn3zyCf369eOaa67hqKOOIj8/n5/+9KcAXHTRRbz88svk5+fz5ptv7lRrSCf+vfbai8mTJzNmzBjy8/M566yzKrcZPXo0RUVF9da8BKQ93PchBAmhK0Fz05PAkHS2bahPQ3ZSD/m/F+3Kxz6o0/FqqzF1Uu5OXGKNS5xmjSvWTHdS15e4xLq7OGfOnGlHHHFEtWVq2km92z6I8KG4s8zsSqCIoP8hqwU1CG9ics41Dr/+9a+5++67663vocJur3JmVkYwrLcLBXcxeROTc03RZZddxkEHHbTT57777st0WNWaOHEiX3zxBUccUb+X6nTvYnpf0jPA48DmioVm9lS9RhMTXoNwrum66667Mh1Co5FugmgNrAWOTlhmBK8LzSolZeWUlZvXIJxzTV66rxzN+n6HCttKg3uYvQbhnGvq0n2S+j5JU5I/aWw3StI8SQsk7fLKUEk9JE2XNFtSoaSu4fKDJL0paU647qxd954ZW0uC14229ttcncuo2o7mCvCHP/yhciwlV7V0vwb/G/hP+JkO7ElwR1OVwruf7gJOAPoC50jqm1TsVuBBMxsA3Aj8KlxeDHzfzPoBo4A/JL6wKJMqaxD+oJxzGdVUEkRpaWmmQ6hSWlc5M3sy4fMwcCZQ5atGQ4OBBWa2yMy2A1OBk5PK9AVeCqdnVKw3s8/MbH44vQJYDeyVTqxR8xqEc41D4miuV111FbfccguHHHIIAwYM4LrrrgNg8+bNfPe73yU/P58DDzyQRx99lDvuuIMVK1YwYsQIRowYUeX+L7nkEgYNGkS/fv0q9wcwc+ZMDj/8cPLz8xk8eDCbNm2irKyMK6+8kgMPPJABAwbwxz/+EdgxcizAu+++y/DhwwG4/vrrGTt2LEOHDmXs2LF8/vnnDBs2jIEDBzJw4MDKEWEBfvOb39C/f38OP/zwyt954MCBlevnz5+/03x9qu2g472BvXdT5pvA0oT5ZcChSWU+BMYAtwOnAu0kdTaztRUFJA0meDnRwuQDSJoATADIy8ur1dgoFYqKitLafsnGIEF89ulcCtfvOvhX1NKNszGIS6xxiRMaV6zt27evHOqi1YzraLZ6TuW6PQxK6/i66vK9+7FtxA1Vrp80aRKzZ8/m1VdfZfr06fzzn/9k+vTpmBlnnXUWzz77LF999RV77bUXU6dOBYIhLNq3b8/vfvc7/vWvf9G5c2fKyspSDtkxceJEOnXqRFlZGSeddBKjRo1iv/3248wzz+S+++6joKCAjRs3Ulpayh133MGCBQt49dVXad68OevWrWPTpk2YGUVFRbRq1YrNmzdXHmvbtm18/PHHPPfcc+yxxx4UFxfz1FNP0bp1axYsWMCFF17Iyy+/zPPPP89TTz3Fiy++SKtWrdiwYQOdOnUiNzeX119/nQEDBnDPPfdwzjnnVDnsSKKtW7fW6N9PWglC0iaCu5YqfEnwjoi6uhK4U9I44BVgOVCWcNx9gIeAC8ysPHljM5sMTAYYNGiQVWTn2igsLCSd7T9cuh7eeJ2B+f0Z3iev1serrXTjbAziEmtc4oTGFevcuXNp165dMNOiJeTsuJyUlpXSPKeOL71p0ZKWFftPITc3l2bNmtGuXTtee+01ZsyYwZFHHgkEiXT58uUMGzaMSZMm8ctf/pLvfe97DBs2DABJ5ObmVo7n1C7FcR5++GEmT55MaWkpK1eu5IsvviA3N5d999238m9Qsd1rr73GZZddRseOHXdannictm3bkpOTQ7t27WjVqhWnnHIKe+8dfM8uLy/n8ssv54MPPiAnJ4fPPvuMdu3a8cYbbzB+/Hjy8vLYtGkTPXr0AODiiy/mscceY8iQITz99NO88847KX+HZK1bt+bggw9O5+wD6d/FtPsj72o50C1hvmu4LHG/KwhqEEjKBU6z8N3XkvYk6PO4xszqPtJWPSkNR2JskeN9EM5VOuHXO81uqeKiGxUz4+qrr+biiy/eZd17773HtGnTmDRpEscccwzXXnvtbve3ePFibr31VmbOnEnHjh0ZN25cytFgdydx9Nbk7RPHYbrtttvIy8vjww8/pLy8nNatW1e739NOO40bbriBo48+moKCAjp37lzj2NKR7l1Mp0pqnzDfQdIpu9lsJtBbUi9JLYGzgWeS9tslHAQQ4GpgSri8JfA0QQf2EzQi20uDilTznDrWn51zdZI4muvxxx/PlClTKCoK7p1Zvnw5q1evZsWKFbRp04bzzz+fq666ivfee2+XbVPZuHEjbdu2pX379qxatYr//ve/AOy///6sXLmSmTNnAsEIr6WlpRx33HHcc889lR3OqUZvffLJJ6s83oYNG9hnn31o1qwZDz30EGVlQUPKcccdx3333VfZoV6x39atW3P88cdzySWX1O/gfEnS/Rp8nZltqJgJv+VfV015zKwUuBx4DpgLPGZmcyTdKGl0WGw4ME/SZ0AecHO4/EzgSGCcpA/Cz0Hp/lJRKikLvg209BqEcxmVOJrrCy+8wLnnnsthhx1G//79Of3009m0aRMfffQRgwcP5qCDDuKGG25g0qRJAEyYMIFRo0ZV2Umdn5/PwQcfzAEHHMC5557L0KFDAWjZsiWPPvooV1xxBfn5+Rx33HFs3bqV8ePH071798pXjD7yyCMAXHfddfz4xz9m0KBB1Q7Bfemll/LAAw+Qn5/Pp59+Wlm7GDVqFKNHj2bQoEEMHTqUW2+9tXKb8847j2bNmjFy5Mh6OZ8pVTWKX+IHmJ1i2UfpbNtQn4YazXX63C+txy/+bR8s+bpOx6utxjSa5+7EJda4xGnWuGL10VwbVnKct9xyi02aNKlG+6j30VxD70r6PcFzDQCXAbPqPVvFgDcxOecy7dRTT2XhwoW89NJLuy9cB+kmiCuA/wc8SnA30wsESSLreBOTc03LiBEjdnlY7aGHHqJ///4Zimj3nn766QY5Trp3MW0GdhkqIxv5XUzONS0zZsxo0Duu4iTdu5heSBzqQlJHSeibd40AABe5SURBVM9FF1bjVeJNTM5VCpqwXRzU5m+V7tfgLhY+nxAe6Gt2/yR1k7Tdm5icA4JbLdeuXetJIgbMjLVr1+72+Ypk6fZBlEvqbmZLACT1ZOcnq7NGaZk3MTkH0LVrV5YtW8aaNWt2Wbd169YaX4wyJS6x1jXO1q1b07Vr1xptk26CuAZ4TdLLgIBhhGMgZZuSMm9icg6gRYsW9OrVK+W6wsLCGg3pkElxiTUTcabbSf2spEEESeF94B/AligDa6y2ew3COZcl0h2sbzzwY4LxlD4AhgBvsvMrSLNCaViD8AThnGvq0r3K/Rg4BPjCzEYABwPrq9+kaSopK6eZIKeZNzE555q2dBPEVjPbCiCplZl9CuwfXViNV0lZudcenHNZId1O6mXhcxD/AF6Q9DXwRXRhNV4lZea3uDrnskK6ndSnhpPXS5oBtAeejSyqRqykrNzvYHLOZYUav/LJzF6OIpC48CYm51y28CtdDZWUmScI51xW8CtdDQU1CG9ics41fZ4gasibmJxz2SLSK52kUZLmSVogaZfhwiX1kDRd0mxJhZK6Jqy7QNL88HNBlHHWhDcxOeeyRWRXOkk5BG+gOwHoC5wjqW9SsVuBB81sAHAj8Ktw204E77w+FBgMXCepY1Sx1oQ3MTnnskWUX4UHAwvMbJGZbQemAicnlekLVLwzb0bC+uOBF8xsXTi0+AvAqAhjTZs3MTnnskWNb3OtgW8CSxPmlxHUCBJ9CIwBbgdOBdpJ6lzFtt9MPoCkCYSjyubl5VFYWFjrYIuKitLa/qt1W8gRdTpWXaQbZ2MQl1jjEifEJ9a4xAnxiTUTcUaZINJxJXCnpHHAK8ByoCzdjc1sMjAZYNCgQTZ8+PBaB1JYWEg62/9hzuu0a92c4cOTc13DSDfOxiAuscYlTohPrHGJE+ITaybijDJBLAe6Jcx3DZdVMrMVBDUIJOUCp5nZeknLgeFJ2xZGGGvaSsrKfagN51xWiPJKNxPoLamXpJbA2cAziQUkdZFUEcPVwJRw+jlgZPju647AyHBZxpX6XUzOuSwR2ZXOzEqBywku7HOBx8xsjqQbJY0Oiw0H5kn6DMgDbg63XQfcRJBkZgI3hssyzsdics5li0j7IMxsGjAtadm1CdNPAE9Use0UdtQoGo3t3sTknMsSfqWrIW9ics5lC7/S1ZA3MTnnsoUniBra7g/KOeeyhF/paqi0zGjZ3E+bc67p8ytdDZWUldO8mTcxOeeaPk8QNWBmlJZ7J7VzLjv4la4GSsoMwJuYnHNZwa90NVBSVg7gTUzOuazgCaIGKhKENzE557KBX+lqoKKJqYU3MTnnsoBf6WqgsgbhTUzOuSzgCaIGvInJOZdN/EpXA97E5JzLJn6lqwFvYnLOZRNPEDXgTUzOuWziV7oa8CYm51w28StdDXgTk3Mum0SaICSNkjRP0gJJE1Os7y5phqT3Jc2WdGK4vIWkByR9JGmupKujjDNdlQnCaxDOuSwQ2ZVOUg5wF3AC0Bc4R1LfpGKTCN5VfTBwNvCncPkZQCsz6w8UABdL6hlVrOkqrWhi8j4I51wWiPJKNxhYYGaLzGw7MBU4OamMAXuG0+2BFQnL20pqDuwBbAc2RhhrWrb7WEzOuSwiM4tmx9LpwCgzGx/OjwUONbPLE8rsAzwPdATaAsea2SxJLYCHgGOANsBPzGxyimNMACYA5OXlFUydOrXW8RYVFZGbm1ttmXdWlvKnD7dx89A9+Ga7zNQi0omzsYhLrHGJE+ITa1zihPjEGlWcI0aMmGVmg1KuNLNIPsDpwF8S5scCdyaV+Snws3D6MOATglrNUOBhoAWwNzAP+FZ1xysoKLC6mDFjxm7LPP3eMuvxi3/bojVFdTpWXaQTZ2MRl1jjEqdZfGKNS5xm8Yk1qjiBd62K62qUX4OXA90S5ruGyxJdCDwGYGZvAq2BLsC5wLNmVmJmq4HXgdQZrgF5E5NzLptEmSBmAr0l9ZLUkqAT+pmkMksImpGQ1IcgQawJlx8dLm8LDAE+jTDWtFTcxeQvDHLOZYPIrnRmVgpcDjwHzCW4W2mOpBsljQ6L/Qy4SNKHwN+BcWGV5y4gV9IcgkRzn5nNjirWdPldTM65bNI8yp2b2TRgWtKyaxOmPyHob0jerojgVtdGpfKNcjnexOSca/r8q3ANVPRBtPQahHMuC/iVrga8ick5l038SlcDJWXlSJDjdzE557KAJ4ga2F5W7rUH51zW8KtdDZSWmfc/OOeyhl/taqCkrNzvYHLOZQ1PEDVQ4k1Mzrks4le7GijxJibnXBbxq10NeBOTcy6beIKoAW9ics5lE7/a1UBJmXmCcM5lDb/a1UBQg/AmJudcdvAEUQPexOScyyZ+tauBoInJaxDOuezgCaIGvAbhnMsmfrWrgQZLEMXroGg1lJXsWJY47ZxzDSDSq52kUZLmSVogaWKK9d0lzZD0vqTZkk5MWDdA0puS5kj6SFLrKGNNR2nUTUzbN8M/LoXf9oJbe8PtB8HiV+H5SfCrrrDwpeiO7ZxzSSJ7o5ykHIJXhx4HLANmSnomfItchUkEryK9W1JfgrfP9ZTUHPgbMNbMPpTUGcj4V+jtZeU0j6oGUboN/joSVs2BIZdCx17w1l3wwPeC9a3bwz+vIGfALdEc3znnkkT5ytHBwAIzWwQgaSpwMpCYIAzYM5xuD6wIp0cCs83sQwAzWxthnGkrKSuPbqiNBdNh1cdw6mTIPytYln8WzPgV9DgM2u0LU0bSe/69cPQoaJYUx9x/wbJ3d8zv0REGXwQt20YTr3OuyZOZRbNj6XRglJmND+fHAoea2eUJZfYBngc6Am2BY81slqT/BQqAvYG9gKlm9tsUx5gATADIy8srmDp1aq3jLSoqIjc3t9oyP5lRzIFdcriwf6taH6cqB8y9jc5rZ/HG4fdjzVLn7V6L/kaPJY+zruNBLOk+Bgiau/JWvcw+X75IuZpXLmtmJWxu05U5/X5BcdvuYOW02zSfnLJtO+2zLKc1m9r1BtV/01k657QxiEucEJ9Y4xInxCfWqOIcMWLELDMblGpdlDWIdJwD3G9mv5N0GPCQpAPDuI4ADgGKgemSZpnZ9MSNzWwyMBlg0KBBNnz48FoHUlhYyO6216sv0KPbNxg+vH+tj5NS6TZ4cyz0P5mjjj626nJHHcW8v3dh/4VT6PThtTuvG3YlzYZfDTnhn3RRIW2fvIjBH/wCRt4Enz0P859Lvd+jJ8GRV9XLr5IonXPaGMQlTohPrHGJE+ITaybijDJBLAe6Jcx3DZcluhAYBWBmb4Yd0V0I+ixeMbOvACRNAwYC08mg7aXltMzJqf8dL3wJtm2EvqdWX05i5b6j2P/Ey2D9FzuWt90b9tpv57LfGg4/eg2evBD+8zPIaQkjfwn7HrxzubfuhsLfwP4nQl6/YFl5Gbz8W3jzTijbnjqWjr3g1D/DNwfW5Dd1zsVIlAliJtBbUi+CxHA2cG5SmSXAMcD9kvoArYE1wHPAzyW1AbYDRwG3RRhrWraXldOieQR3Mc35B7TuAN86Kr3yHboFn91plwff/ye8/1CQGPbJ37XMXgfAXYfCI2fvSBAbl8GXH8EB34MuvXfdxgw+egKmHA8jbw76OiJoonLOZVZkCcLMSiVdTnCxzwGmmNkcSTcC75rZM8DPgHsl/YSgw3qcBZ0iX0v6PUGSMWCamf0nqljTYWZsLy2nVRSd1F+8Ad8eATkt6n/fzXKgYFzV69t2gdPuhZd+CRvDCl6zFnDyn+Dg86rebuiP4ekfwX+vgs9fgV67Jrd9l8+Hd+bXLf666Dpo1xqTcy5tkfZBmNk0gltXE5ddmzD9CTC0im3/RnCra6NQUhZ05rdsXs8JongdbFgCh/ywfvdbE98+OvjURJtOcM5UePOPMP3G4C6qJPsBZDA/oGYw4ho4cEy1xVpvWQnrFkUcSw506O41LRcrme6kjo3tZeVABAli1cfBz28MqN/9NoRmzYKaxKALoWTLLqtff+N1hh6eMv9Hr2wbPP//4KWbgk81hgC83QAxffsYGDM5qLU5FwOeINK0vTRMEPXdxLRydvAzjgmiQqvc4JOkpGUHyN0rAwGFTp8CB58Pm9dUW2zu3Ln06dMn2lg2LIWXb4E7BkLbzrXezeAtW2D2HvUYWDTiEifKoVv7w6H8yF2fLXKeINJVmSCa1/NdTF9+BO32yeyFtKmS4DvH7LbYqq8L6ZM/PPp4eh8Pb98T1G5qadOqVbTJy6vHoKIRlzjZuJJvL3oAHlwU3LDRiPVevhw2/zv1yg7dYej/1PsxPUGkqSRsYqr3sZi+nB3v2oNL3z4D4JS76rSLuYWF5MXgnv24xIkZ8x/+Ob1X/SsY5qYR27ukBL6u4kaWfQ/yBJFJ20oj6IMo2Qpr5gXPIDjnGp7E8q7fpff5jX+Ms9cz8KCcN7qlqaKJqVV9JojVn4CVBd8snXOukfEEkaZa38W09B14fBys/HDXdfNfCH56E5NzrhHyBJGmHXcx1aCT+p174b4TYM7T8JfjYOZfg6eQS7bAv34Mhf8XPGDWsWc0QTvnXB14H0SaSmpagygvg2cnQvfD4KTbYdpV8J+fwuJXYO1CWPURHPGT4EEuf3jKOdcIeYJIU0UNIu27mIrXQXkp9DkJOn8bznsCXvs9zLg5ePnPuY/DfiMjjNg55+rGE0Saqr2LqXQ7PHwajJgE3Q8NlhV/FfyseGq2WTM48ko44LuwR6dgID3nnGvEvA8iTRWd1CnvYtq4PGg6WjZzx7LNYYJokzSswt59PDk452LBE0Saqu2k3rIu+Jk4HlHF8A4+7o5zLqY8QaRpe3VNTMVfBz9LihOWha/RbutDaDjn4skTRJqqvYspZQ0ibGLao1PEkTnnXDQ8QaSp2ruYiisSRGIN4ivYo+OOd0Q751zMeIJIU7VPUlfVB+HNS865GIs0QUgaJWmepAWSJqZY313SDEnvS5ot6cQU64skXRllnOnYVt37IFLVIDav3fUOJueci5HIEoSkHOAu4ASgL3COpL5JxSYBj5nZwcDZwJ+S1v8e+G9UMdbE9tJyWuY0Q6meek5Vgyj+qk4vhnHOuUyLsgYxGFhgZovMbDswFTg5qYwBe4bT7YEVFSsknQIsBhrFIO0lZeVVD7OxJcVdTJu/8hqEcy7WZGbR7Fg6HRhlZuPD+bHAoWZ2eUKZfYDngY5AW+BYM5slKRd4ATgOuBIoMrNbUxxjAjAhnN0fmFeHkLsAX9Vh+4YSlzghPrHGJU6IT6xxiRPiE2tUcfYws5Qdppm+xeYc4H4z+52kw4CHJB0IXA/cZmZFKZt0QmY2GZhcH4FIetfMBtXHvqIUlzghPrHGJU6IT6xxiRPiE2sm4owyQSwHuiXMdw2XJboQGAVgZm9Kak2QJQ8FTpf0W6ADUC5pq5ndGWG8zjnnEkSZIGYCvSX1IkgMZwPnJpVZAhwD3C+pD9AaWGNmwyoKSLqeoInJk4NzzjWgyDqpzawUuBx4DphLcLfSHEk3ShodFvsZcJGkD4G/A+Msqk6R3auXpqoGEJc4IT6xxiVOiE+scYkT4hNrg8cZWSe1c865ePMnqZ1zzqXkCcI551xKWZ8gdjccSCZJ6hYORfKJpDmSfhwuv17SckkfhJ8Td7evBoj1c0kfhfG8Gy7rJOkFSfPDnx0bQZz7J5y3DyRtlPS/jeGcSpoiabWkjxOWpTyHCtwR/rudLWlgI4j1FkmfhvE8LalDuLynpC0J5/bPGY6zyr+1pKvDczpP0vENFWc1sT6aEOfnkj4IlzfMOTWzrP0AOcBC4FtAS+BDoG+m40qIbx9gYDjdDviMYNiS64ErMx1fUqyfA12Slv0WmBhOTwR+k+k4U/z9vwR6NIZzChwJDAQ+3t05BE4kGIZGwBDg7UYQ60igeTj9m4RYeyaWawRxpvxbh/+3PgRaAb3Ca0NOJmNNWv874NqGPKfZXoNIZziQjDGzlWb2Xji9ieBusG9mNqoaORl4IJx+ADglg7Gkcgyw0My+yHQgAGb2CrAuaXFV5/Bk4EELvAV0CEcmaBCpYjWz5y24exHgLYJnnzKqinNalZOBqWa2zcwWAwsIrhENorpYFTwxfCbB3Z4NJtsTxDeBpQnzy2ikF2BJPYGDgbfDRZeHVfkpjaHphmBcreclzQqHQAHIM7OV4fSXQGN7GffZ7PwfrrGdU6j6HDb2f7s/ZOeBNnspGLX5ZUnDqtqoAaX6WzfmczoMWGVm8xOWRX5Osz1BxIKCsameBP7XzDYCdwPfBg4CVhJUPTPtCDMbSDB672WSjkxcaUG9uNHcUy2pJTAaeDxc1BjP6U4a2zmsiqRrgFLg4XDRSqC7BaM2/xR4RNKeVW3fABr93zqFc9j5y0yDnNNsTxDpDAeSUZJaECSHh83sKQAzW2VmZWZWDtxLA1aDq2Jmy8Ofq4GnCWJaVdHsEf5cnbkId3EC8J6ZrYLGeU5DVZ3DRvlvV9I44HvAeWFCI2yyWRtOzyJo298vUzFW87durOe0OTAGeLRiWUOd02xPEJXDgYTfKM8GnslwTJXCdse/AnPN7PcJyxPbmk8FPk7etiFJaiupXcU0QWflxwTn8oKw2AXAPzMTYUo7fSNrbOc0QVXn8Bng++HdTEOADQlNURkhaRTwc2C0mRUnLN9LwfthkPQtoDewKDNRVvu3fgY4W1IrBUME9Qbeaej4UjgW+NTMllUsaLBz2lA99I31Q3A3yGcEGfiaTMeTFNsRBE0Ks4EPws+JwEPAR+HyZ4B9Mhzntwju/viQ4P0d14TLOwPTgfnAi0CnTJ/TMK62wFqgfcKyjJ9TgoS1EighaP++sKpzSHD30l3hv9uPgEGNINYFBG34Ff9W/xyWPS38d/EB8B5wUobjrPJvDVwTntN5wAmZPqfh8vuBHyWVbZBz6kNtOOecSynbm5icc85VwROEc865lDxBOOecS8kThHPOuZQ8QTjnnEvJE4SLLUlFCdP7hKNwnpTJmJxrSjxBuNgLH9KbRjB66L8yHY9zTYUnCBdr4VAkTwHPmNm9CcvPUfB+io8l/SZpm7JwDP0Fkv4dLrtf0unh9HhJJqmLpOEVZcJ1n0vqEk6fL+mdcF/3JDzZOkrSe5I+lDRd0h4J4/Zv1473ZgwKj7s4jHO2pAPDfRwk6S3teLfCLoMHSno1PM7rko4Ilw2XtCHheMslXV/VPiU1lzRT0vCwzK8k3Vx/fyEXZ54gXNxNAY5i52Ez9iV4H8HRBAOyHSLplHBdDrDZzA4CxifvTFJr4EfsGPOonOCp5eRyfYCzgKHhvsqA8yTtRTC+z2lmlg+cYWZbzOygsNwKYEQ4/264u6vM7EDglTBmgAeBX5jZAIKnfq9L8bsfa8EAiacCfwwHdQR4NeF4tyWU32WfFgzPPQ64W9KxwCjghhTHclnIE4SLs7YEQ1GMIxh2osIhQKGZrQkvgA8TvIwFYA9gazX7vIzgvQtbwvllQJ8wcSQ6BigAZip4y9cxBEOODAFeseB9AphZOu8iuEXSfMLRZSW1BzqY2cvh+gcS4k90Unjs5wlecHNwVQeobp9mNodg+Il/Az+04N0oznmCcLG2jeAb+iNAqaTz0thmX4Jv8ansSTBg4z0VC8xsEfAI8F54Md43XCXggYpv6ma2v5ldX8vf4yoz6w3cSA2+vZvZEwk1hQ9qeewK/YH1wN513I9rQjxBuDgrNbPN4fRlwM3hN+V3gKPCPoQcgpFbK745nwm8XsX+fgL8MfkbtJlNMrO+CU1EEAygd7qkvaHy3dE9CN6kdmQ4GiiSOtXg99lI8NrWDcDX2vESmLEJ8VdKGAZ8EMFQz+9XtePq9ilpDNCJoEbxR4XvknaueaYDcK4+mNkCSfcB/2dml0maCMwg+Kb/HzP7p6T/AYayY/jsZAL+lubxPpE0ieAtes0IRuC8zMzeUvBGvafC5auB43azu1vCfRk7+kUuAP4sqQ3BMM4/SLHdU+Hw6mXAOWZWJO3SXZJol32GHe6/Bo4xs6WS7gRup+pz5LKIj+bqnHMuJW9ics45l5InCOeccyl5gnDOOZeSJwjnnHMpeYJwzjmXkicI55xzKXmCcM45l9L/B8rKjZhZc4SqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLkRrArys01d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whpo2_5rs06j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-dH5YGns1CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4nyyLLms1AG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwZI7f0us09p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dP3BLUQs05g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVkqhr_5s0y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}